{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atari gym environment\n",
    "Random policy for MsPacman Pong and Boxing\n",
    "\n",
    "\n",
    "# To load model, run cells at bottom of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pdb\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from datetime import datetime\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Convert the 4 210x160x3 uint8 frames into a single agent state, size 28x28x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(observation):\n",
    "    resized = resize(observation, (28, 28), preserve_range=True)\n",
    "    return rgb2gray(resized).astype(\"uint8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the state for an environment, need to get the firs four frames and stack them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_init_state(env):\n",
    "    state_list = []\n",
    "    observation = env.reset()\n",
    "    for _ in range(4):\n",
    "        state_list.append(preprocess(observation))\n",
    "        action = env.action_space.sample()\n",
    "        observation, _, _, info = env.step(action)\n",
    "    state = np.stack(state_list, axis=2)\n",
    "    return env, state, observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to keep four frames at a time, each time we see a new state we need to drop the oldest and add the newest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_state(state, observation):\n",
    "    state = np.append(state, preprocess(observation).reshape(28, 28, 1), axis=2)\n",
    "    new_state = state[:, :, 1:]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip_rewards(reward):\n",
    "    if reward > 0:\n",
    "        return 1\n",
    "    elif reward < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(x, W, b, stride=2):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    conv = tf.nn.relu(tf.nn.bias_add(conv, b))\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q- network to estimate the action value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Q_net(state, action, n_act, alpha=0.001):\n",
    "    weights = {\n",
    "        'conv1': tf.Variable(tf.truncated_normal([6, 6, 4, 16], 0, 0.01)),\n",
    "        'conv2': tf.Variable(tf.truncated_normal([4, 4, 16, 32], 0, 0.01)),\n",
    "        'hidden': tf.Variable(tf.truncated_normal([7*7*32, 256], 0, 0.01)),\n",
    "        'output': tf.Variable(tf.truncated_normal([256, n_act], 0, 0.01))\n",
    "    }\n",
    "    biases = {\n",
    "        'conv1': tf.Variable(tf.constant(0.1, shape=[16])),\n",
    "        'conv2': tf.Variable(tf.constant(0.1, shape=[32])),\n",
    "        'hidden': tf.Variable(tf.constant(0.1, shape=[256])),\n",
    "        'output': tf.Variable(tf.constant(0.1, shape=[n_act]))\n",
    "    }\n",
    "\n",
    "    # Convolutional layers (with ReLU)\n",
    "    conv1 = conv_layer(state, weights['conv1'], biases['conv1'], stride=2)\n",
    "    conv2 = conv_layer(conv1, weights['conv2'], biases['conv2'], stride=2)\n",
    "    conv2_flat = tf.reshape(conv2,  [-1, 7*7*32])\n",
    "\n",
    "    # Fully connected layers\n",
    "    fc = tf.nn.relu(tf.matmul(conv2_flat, weights['hidden']) + biases['hidden'])\n",
    "    q = tf.matmul(fc, weights['output']) + biases['output']\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "test_episodes = 100\n",
    "max_eps_length = 10000000\n",
    "gamma = 0.99\n",
    "epsilon = 0.01\n",
    "game = 'Boxing-v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_tf_vars():\n",
    "    state = tf.placeholder(\"float\", [None,28, 28, 4])\n",
    "    action = tf.placeholder(tf.int32, [None, 2])\n",
    "    reward = tf.placeholder(\"float\", [None, 1])\n",
    "    return state, action, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-11 22:45:04,342] Making new env: Boxing-v3\n"
     ]
    }
   ],
   "source": [
    "this_env = gym.make(game)  # for evaluation\n",
    "n_act = this_env.action_space.n\n",
    "alpha = 0.001\n",
    "state, action, reward   = init_tf_vars()\n",
    "q = Q_net(state, action, n_act, alpha=alpha)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start = time.time()\n",
    "    score_list = []\n",
    "    frame_count_list =[]\n",
    "    \n",
    "\n",
    "    print(\"\\n#------ Running 100 episodes for testing\")\n",
    "    for episode in range(test_episodes):\n",
    "        score  = frame_count  = 0\n",
    "        print('Running episode:{}'.format(episode+1))\n",
    "        print(\"#------- Total time elapsed = %s\\n\" % str(time.time()-start))\n",
    "        this_env, s_test, test_obs = get_init_state(this_env)\n",
    "\n",
    "        for test_t in range(max_eps_length):\n",
    "            q_now = sess.run(q, feed_dict={state: s_test.reshape(1, 28, 28, 4)})\n",
    "            a = np.argmax(q_now)\n",
    "            next_test_obs, test_r, done, info = this_env.step(a)\n",
    "            \n",
    "\n",
    "            if test_r > 0:\n",
    "                score += test_r\n",
    "\n",
    "\n",
    "            s_prime_test = update_state(s_test, test_obs)\n",
    "\n",
    "            if done:\n",
    "                score_list.append(score)\n",
    "                frame_count_list.append(test_t+1)\n",
    "                break\n",
    "            s_test = s_prime_test\n",
    "            test_obs = next_test_obs\n",
    "\n",
    "    # Print results\n",
    "    results_list = (np.mean(np.array(score_list)), np.std(np.array(score_list)), \n",
    "                     np.mean(np.array(frame_count_list)), np.std(np.array(frame_count_list)))\n",
    "    print(\"\\nMean score = %f, stdev score = %f, mean frame count = %f, stdev frame count = %f\" % results_list)\n",
    "    # Save performance and loss results\n",
    "    saved_results = list(results_list)\n",
    "    filename = './results/B2results_'+game+'.npy'\n",
    "    #np.save(filename, saved_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def totuple(a):\n",
    "    try:\n",
    "        return tuple(totuple(i) for i in a)\n",
    "    except TypeError:\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for MsPacman-V3 were:\n",
      "Mean score = 165.400000, stdev score = 112.751231, mean frame count = 650.020000, stdev frame count = 104.148066\n",
      "\n",
      "The results for Pong-V3 were:\n",
      "Mean score = 0.300000, stdev score = 2.100000, mean frame count = 1126.480000, stdev frame count = 674.100133\n",
      "\n",
      "The results for Boxing-V3 were:\n",
      "Mean score = 14.560000, stdev score = 2.150907, mean frame count = 2376.450000, stdev frame count = 13.150190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "games = ['MsPacman-V3','Pong-V3','Boxing-V3']\n",
    "for i in range(3):\n",
    "    game =games[i]\n",
    "    filename = './results/B2results_'+game+'.npy'\n",
    "    restored_data = np.load(filename)\n",
    "    print('The results for {} were:'.format(game))\n",
    "    print(\"Mean score = %f, stdev score = %f, mean frame count = %f, stdev frame count = %f\\n\" % totuple(restored_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Assignment_3]",
   "language": "python",
   "name": "conda-env-Assignment_3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
