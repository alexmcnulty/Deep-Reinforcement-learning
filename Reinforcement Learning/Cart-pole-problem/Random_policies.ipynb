{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1\n",
    "Generate three trajectories under a uniform random policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import random\n",
    "import pdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import _pickle as pickle\n",
    "import gym\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-08 13:21:05,667] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env._max_episode_steps = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to loop through the episode 3 times and ouput the returns from initial state and length of episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This episode lasted 29 steps with a return of -0.7547192872036326\n",
      "\n",
      "This episode lasted 26 steps with a return of -0.7778213593991467\n",
      "\n",
      "This episode lasted 24 steps with a return of -0.7936142836436554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "episode_data = []\n",
    "episode_lengths = []\n",
    "episode_returns = []\n",
    "for i_episode in range(3):\n",
    "        gamma = 0.99\n",
    "        episode_return = 0\n",
    "        episode_length = 0\n",
    "        s = env.reset()\n",
    "\n",
    "        for t in range(300):\n",
    "            # define the discount\n",
    "            gamma_t = gamma ** t\n",
    "            # see the game\n",
    "            #env.render()\n",
    "            action = env.action_space.sample()  \n",
    "            s_prime, reward, done, info = env.step(action)\n",
    "\n",
    "            if done:\n",
    "                # episode terminates, then get return and record episode length\n",
    "                episode_length = t + 1\n",
    "                episode_lengths.append(episode_length)\n",
    "                episode_return += (-1 * gamma_t)  # -1 reward for terminating time-steps\n",
    "                episode_returns.append(episode_return)\n",
    "                episode_data.append(np.append(s, np.array([action, -1, i_episode])))\n",
    "                print('This episode lasted {} steps with a return of {}\\n'.format(episode_length, episode_return))\n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                episode_return += 0  # 0 reward for non-terminating time-steps\n",
    "                episode_data.append(np.append(s, np.array([action, 0, i_episode])))\n",
    "            s = s_prime\n",
    "saved_data  = np.concatenate((np.asarray(episode_lengths).reshape(-1,1), np.asarray(episode_returns).reshape(-1,1)), axis=1)\n",
    "filename = './results/A1results.npy'\n",
    "#np.save(filename, saved_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the lengths of restored episodes are : [[ 29.  26.  24.]]\n",
      " the lengths of restored returns are : [[-0.75471929 -0.77782136 -0.79361428]]\n"
     ]
    }
   ],
   "source": [
    "restored_data = np.load(filename)\n",
    "print(' the lengths of restored episodes are : {}'.format(restored_data[:,0].reshape(1,-1)))\n",
    "print(' the lengths of restored returns are : {}'.format(restored_data[:,1].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for 100 episodes and take the mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This episode lasted 10 steps with a return of -0.9135172474836408\n",
      "\n",
      "This episode lasted 57 steps with a return of -0.5696012024771592\n",
      "\n",
      "This episode lasted 14 steps with a return of -0.8775210229989678\n",
      "\n",
      "This episode lasted 21 steps with a return of -0.8179069375972308\n",
      "\n",
      "This episode lasted 9 steps with a return of -0.9227446944279201\n",
      "\n",
      "This episode lasted 22 steps with a return of -0.8097278682212584\n",
      "\n",
      "This episode lasted 27 steps with a return of -0.7700431458051551\n",
      "\n",
      "This episode lasted 12 steps with a return of -0.8953382542587164\n",
      "\n",
      "This episode lasted 16 steps with a return of -0.8600583546412884\n",
      "\n",
      "This episode lasted 12 steps with a return of -0.8953382542587164\n",
      "\n",
      "This episode lasted 13 steps with a return of -0.8863848717161292\n",
      "\n",
      "This episode lasted 12 steps with a return of -0.8953382542587164\n",
      "\n",
      "This episode lasted 29 steps with a return of -0.7547192872036326\n",
      "\n",
      "This episode lasted 51 steps with a return of -0.6050060671375364\n",
      "\n",
      "This episode lasted 22 steps with a return of -0.8097278682212584\n",
      "\n",
      "This episode lasted 17 steps with a return of -0.8514577710948755\n",
      "\n",
      "This episode lasted 18 steps with a return of -0.8429431933839268\n",
      "\n",
      "This episode lasted 20 steps with a return of -0.8261686238355866\n",
      "\n",
      "This episode lasted 22 steps with a return of -0.8097278682212584\n",
      "\n",
      "This episode lasted 27 steps with a return of -0.7700431458051551\n",
      "\n",
      "This episode lasted 18 steps with a return of -0.8429431933839268\n",
      "\n",
      "This episode lasted 19 steps with a return of -0.8345137614500875\n",
      "\n",
      "This episode lasted 23 steps with a return of -0.8016305895390459\n",
      "\n",
      "This episode lasted 17 steps with a return of -0.8514577710948755\n",
      "\n",
      "This episode lasted 16 steps with a return of -0.8600583546412884\n",
      "\n",
      "This episode lasted 18 steps with a return of -0.8429431933839268\n",
      "\n",
      "This episode lasted 17 steps with a return of -0.8514577710948755\n",
      "\n",
      "This episode lasted 17 steps with a return of -0.8514577710948755\n",
      "\n",
      "This episode lasted 23 steps with a return of -0.8016305895390459\n",
      "\n",
      "This episode lasted 30 steps with a return of -0.7471720943315961\n",
      "\n",
      "This episode lasted 16 steps with a return of -0.8600583546412884\n",
      "\n",
      "This episode lasted 25 steps with a return of -0.7856781408072188\n",
      "\n",
      "This episode lasted 11 steps with a return of -0.9043820750088044\n",
      "\n",
      "This episode lasted 20 steps with a return of -0.8261686238355866\n",
      "\n",
      "This episode lasted 10 steps with a return of -0.9135172474836408\n",
      "\n",
      "This episode lasted 26 steps with a return of -0.7778213593991467\n",
      "\n",
      "This episode lasted 17 steps with a return of -0.8514577710948755\n",
      "\n",
      "This episode lasted 20 steps with a return of -0.8261686238355866\n",
      "\n",
      "This episode lasted 28 steps with a return of -0.7623427143471035\n",
      "\n",
      "This episode lasted 31 steps with a return of -0.7397003733882802\n",
      "\n",
      "This episode lasted 19 steps with a return of -0.8345137614500875\n",
      "\n",
      "This episode lasted 26 steps with a return of -0.7778213593991467\n",
      "\n",
      "This episode lasted 12 steps with a return of -0.8953382542587164\n",
      "\n",
      "This episode lasted 12 steps with a return of -0.8953382542587164\n",
      "\n",
      "This episode lasted 13 steps with a return of -0.8863848717161292\n",
      "\n",
      "This episode lasted 27 steps with a return of -0.7700431458051551\n",
      "\n",
      "This episode lasted 22 steps with a return of -0.8097278682212584\n",
      "\n",
      "This episode lasted 38 steps with a return of -0.6894490858690777\n",
      "\n",
      "This episode lasted 44 steps with a return of -0.6491026283684022\n",
      "\n",
      "This episode lasted 14 steps with a return of -0.8775210229989678\n",
      "\n",
      "This episode lasted 20 steps with a return of -0.8261686238355866\n",
      "\n",
      "This episode lasted 46 steps with a return of -0.6361854860638709\n",
      "\n",
      "This episode lasted 14 steps with a return of -0.8775210229989678\n",
      "\n",
      "This episode lasted 20 steps with a return of -0.8261686238355866\n",
      "\n",
      "This episode lasted 13 steps with a return of -0.8863848717161292\n",
      "\n",
      "This episode lasted 36 steps with a return of -0.7034476949995692\n",
      "\n",
      "This episode lasted 15 steps with a return of -0.8687458127689782\n",
      "\n",
      "This episode lasted 12 steps with a return of -0.8953382542587164\n",
      "\n",
      "This episode lasted 19 steps with a return of -0.8345137614500875\n",
      "\n",
      "This episode lasted 54 steps with a return of -0.5870367819374844\n",
      "\n",
      "This episode lasted 13 steps with a return of -0.8863848717161292\n",
      "\n",
      "This episode lasted 12 steps with a return of -0.8953382542587164\n",
      "\n",
      "This episode lasted 47 steps with a return of -0.6298236312032323\n",
      "\n",
      "This episode lasted 11 steps with a return of -0.9043820750088044\n",
      "\n",
      "This episode lasted 21 steps with a return of -0.8179069375972308\n",
      "\n",
      "This episode lasted 37 steps with a return of -0.6964132180495735\n",
      "\n",
      "This episode lasted 18 steps with a return of -0.8429431933839268\n",
      "\n",
      "This episode lasted 35 steps with a return of -0.7105532272722921\n",
      "\n",
      "This episode lasted 21 steps with a return of -0.8179069375972308\n",
      "\n",
      "This episode lasted 17 steps with a return of -0.8514577710948755\n",
      "\n",
      "This episode lasted 22 steps with a return of -0.8097278682212584\n",
      "\n",
      "This episode lasted 15 steps with a return of -0.8687458127689782\n",
      "\n",
      "This episode lasted 9 steps with a return of -0.9227446944279201\n",
      "\n",
      "This episode lasted 25 steps with a return of -0.7856781408072188\n",
      "\n",
      "This episode lasted 11 steps with a return of -0.9043820750088044\n",
      "\n",
      "This episode lasted 34 steps with a return of -0.7177305325982749\n",
      "\n",
      "This episode lasted 16 steps with a return of -0.8600583546412884\n",
      "\n",
      "This episode lasted 16 steps with a return of -0.8600583546412884\n",
      "\n",
      "This episode lasted 18 steps with a return of -0.8429431933839268\n",
      "\n",
      "This episode lasted 16 steps with a return of -0.8600583546412884\n",
      "\n",
      "This episode lasted 20 steps with a return of -0.8261686238355866\n",
      "\n",
      "This episode lasted 11 steps with a return of -0.9043820750088044\n",
      "\n",
      "This episode lasted 15 steps with a return of -0.8687458127689782\n",
      "\n",
      "This episode lasted 39 steps with a return of -0.682554595010387\n",
      "\n",
      "This episode lasted 16 steps with a return of -0.8600583546412884\n",
      "\n",
      "This episode lasted 30 steps with a return of -0.7471720943315961\n",
      "\n",
      "This episode lasted 30 steps with a return of -0.7471720943315961\n",
      "\n",
      "This episode lasted 15 steps with a return of -0.8687458127689782\n",
      "\n",
      "This episode lasted 11 steps with a return of -0.9043820750088044\n",
      "\n",
      "This episode lasted 25 steps with a return of -0.7856781408072188\n",
      "\n",
      "This episode lasted 43 steps with a return of -0.6556592205741436\n",
      "\n",
      "This episode lasted 14 steps with a return of -0.8775210229989678\n",
      "\n",
      "This episode lasted 19 steps with a return of -0.8345137614500875\n",
      "\n",
      "This episode lasted 15 steps with a return of -0.8687458127689782\n",
      "\n",
      "This episode lasted 20 steps with a return of -0.8261686238355866\n",
      "\n",
      "This episode lasted 23 steps with a return of -0.8016305895390459\n",
      "\n",
      "This episode lasted 14 steps with a return of -0.8775210229989678\n",
      "\n",
      "This episode lasted 23 steps with a return of -0.8016305895390459\n",
      "\n",
      "This episode lasted 12 steps with a return of -0.8953382542587164\n",
      "\n",
      "This episode lasted 13 steps with a return of -0.8863848717161292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "episode_data = []\n",
    "episode_lengths = []\n",
    "episode_returns = []\n",
    "for i_episode in range(100):\n",
    "        gamma = 0.99\n",
    "        episode_return = 0\n",
    "        episode_length = 0\n",
    "        s = env.reset()\n",
    "\n",
    "        for t in range(300):\n",
    "            # define the discount\n",
    "            gamma_t = gamma ** t\n",
    "            # see the game\n",
    "            #env.render()\n",
    "            action = env.action_space.sample()  \n",
    "            s_prime, reward, done, info = env.step(action)\n",
    "\n",
    "            if done:\n",
    "                # episode terminates, then get return and record episode length\n",
    "                episode_length = t + 1\n",
    "                episode_lengths.append(episode_length)\n",
    "                episode_return += (-1 * gamma_t)  # -1 reward for terminating time-steps\n",
    "                episode_returns.append(episode_return)\n",
    "                episode_data.append(np.append(s, np.array([action, -1, i_episode])))\n",
    "                print('This episode lasted {} steps with a return of {}\\n'.format(episode_length, episode_return))\n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                episode_return += 0  # 0 reward for non-terminating time-steps\n",
    "                episode_data.append(np.append(s, np.array([action, 0, i_episode])))\n",
    "            s = s_prime\n",
    "            \n",
    "results = []\n",
    "mean_lengths = np.mean(episode_lengths)\n",
    "std_lengths = np.std(episode_lengths)\n",
    "mean_returns = np.mean(episode_returns)\n",
    "std_returns = np.std(episode_returns)\n",
    "results.append(mean_lengths)\n",
    "results.append(std_lengths)\n",
    "results.append(mean_returns)\n",
    "results.append(std_returns)\n",
    "\n",
    "#results = \n",
    "#saved_data  = np.concatenate((np.meannp.asarray(episode_lengths).reshape(-1,1), np.asarray(episode_returns).reshape(-1,1)), axis=1)\n",
    "filename = './results/A2results.npy'\n",
    "#np.save(filename, np.asarray(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the mean lengths of restored episodes are : 21.31 wth standard deviation:10.243724908450051\n",
      " the mean returns of restored episodes are : -0.81948036439169 wth standard deviation:0.07835583319644615\n"
     ]
    }
   ],
   "source": [
    "filename = './results/A2results.npy'\n",
    "restored_data = np.load(filename)\n",
    "print(' the mean lengths of restored episodes are : {} wth standard deviation:{}'.format(restored_data[0],restored_data[1]))\n",
    "print(' the mean returns of restored episodes are : {} wth standard deviation:{}'.format(restored_data[2],restored_data[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Assignment_3]",
   "language": "python",
   "name": "conda-env-Assignment_3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
