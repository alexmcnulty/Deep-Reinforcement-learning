{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1: Many to one Model:LSTM128\n",
    "In this task we classifiy the MNSIT data set by using a RNN of different sizes and differnt cells. The binarized images are passed into the RNN cell one pixel at a time and the final output is taken. Here the output is transformed into fully connected layer of 100 units with a ReLU activation function. It \n",
    "is then passed through another linear layer of width 10 and a softmax operation is used to get the probabilites of each digit. Cross entropy loss function is used for the cost and the Adam optimizer is used to minimize this value.\n",
    "\n",
    "It was noted that the lstm cell was quite unstable and did not perform as well as the GRU cell over the same number of epochs. Many different learning rates turned out to be too small to learn anything in time or to large such that it would quite well for some time till it jumped to much and lost all accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Need to load the MNist data to work with\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)\n",
    "# one hot true gives the y labels as vectors with 1's which correspond to the number it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data that we will be working with:\n",
      "train set: 55000 \n",
      "valid set: 5000 \n",
      "test set: 10000 \n"
     ]
    }
   ],
   "source": [
    "print('The size of the data that we will be working with:')\n",
    "print('train set: {} '.format(len(mnist.train.labels)))\n",
    "print('valid set: {} '.format(len(mnist.validation.labels)))\n",
    "print('test set: {} '.format(len(mnist.test.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "batch_size = 128\n",
    "chunk_size = 1\n",
    "n_chunks = 784\n",
    "rnn_size = 128\n",
    "units_output = 100\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# placeholders tp store the inputs and labels \n",
    "x = tf.placeholder('float', [None, n_chunks,chunk_size],name='InputData')\n",
    "y = tf.placeholder('float',name='LabelData')\n",
    "\n",
    "logs_path = '/tmp/tensorflow_logs/example'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the varibles that will be used in to transform the 32d layer to 100d fully connected layer.\n",
    "\n",
    "Then for the second fully connected layer from 100 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer1 = {'weights':tf.Variable(tf.random_normal([rnn_size,units_output]),name='Weights1'),\n",
    "             'biases':tf.Variable(tf.random_normal([units_output]),name='Bias')}\n",
    "\n",
    "layer2 = {'weights':tf.Variable(tf.random_normal([units_output,n_classes]),name='Weights2'),\n",
    "             'biases':tf.Variable(tf.random_normal([n_classes]),name='Bias')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784, 128)\n"
     ]
    }
   ],
   "source": [
    "# Here the lstm cell is defined of specified size\n",
    "lstm_cell = tf.nn.rnn_cell.LSTMCell(rnn_size,state_is_tuple=True)\n",
    "\n",
    "# The ouputs are a tensor of all the ouput states of the pixels\n",
    "outputs, states = tf.nn.dynamic_rnn(cell = lstm_cell, inputs = x,dtype=tf.float32)\n",
    "\n",
    "# Checking to make sure of the correct shape\n",
    "print(outputs.get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Many to one model so we need only the last output of the rnn.\n",
    "outputs = outputs[:, -1, :]\n",
    "\n",
    "# linear transformation\n",
    "output_rnn = tf.matmul(outputs,layer1['weights']) + layer1['biases']\n",
    "\n",
    "# Relu activation\n",
    "act = tf.nn.relu(output_rnn)\n",
    "\n",
    "# linear transformatino\n",
    "output = tf.matmul(act,layer2['weights'])+layer2['biases']\n",
    "\n",
    "# calculate cost of batch\n",
    "Xent =  tf.nn.softmax_cross_entropy_with_logits(output,y)\n",
    "\n",
    "# calculate the average cost per image and optimize\n",
    "with tf.name_scope('Loss'):\n",
    "    cost = tf.reduce_mean( Xent )\n",
    "with tf.name_scope('Adam'):    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a boolean of correct labels and take the average to \n",
    "# get the percentage of correctly available\n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_label = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_label, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to save the model, weights and biases varibles\n",
    "saver = tf.train.Saver(write_version = tf.train.SaverDef.V2)\n",
    "\n",
    "# Suggested Directory to use\n",
    "save_MDir = 'models/lstm32/'\n",
    "\n",
    "\n",
    "#create the directory if it does not exist already\n",
    "if not os.path.exists(save_MDir):\n",
    "    os.makedirs(save_MDir)\n",
    "\n",
    "save_model = os.path.join(save_MDir,'best_accuracyE10_LR0_0005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to save the model, weights and biases varibles\n",
    "saver2 = tf.train.Saver(write_version = tf.train.SaverDef.V2)\n",
    "\n",
    "# Suggested Directory to use\n",
    "save_MDir2 = 'models/lstm32/best/'\n",
    "\n",
    "\n",
    "#create the directory if it does not exist already\n",
    "if not os.path.exists(save_MDir2):\n",
    "    os.makedirs(save_MDir2)\n",
    "\n",
    "save_model2 = os.path.join(save_MDir2,'best_accuracyE10_LR0_0005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(images, threshold=0.1):\n",
    "    return (threshold < images).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "# need to start up the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(hm_epochs):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())        \n",
    "        start_epoch = time.time()\n",
    "        freq_epoch = hm_epochs/30\n",
    "        acc_list = []\n",
    "        count = 0\n",
    "        # For each epoch loop over all batches and optimize the cost and produce the test cost\n",
    "        for epoch in range(hm_epochs):\n",
    "            print(\"-------Running Epoch:{}-------\".format(epoch+1))\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            start = time.time()\n",
    "            n_batches = int(mnist.train.num_examples/batch_size)\n",
    "            #n_batches = 10\n",
    "            # print batch test and train costs.            \n",
    "            freq = int(n_batches/5)\n",
    "            for i in range(n_batches):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                epoch_x = binarize(epoch_x)\n",
    "                epoch_x = epoch_x.reshape((batch_size,n_chunks,chunk_size))\n",
    "\n",
    "\n",
    "                _, c,summary = sess.run([optimizer, cost,merged_summary_op], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                summary_writer.add_summary(summary, epoch * n_batches + i)\n",
    "                epoch_loss += c\n",
    "                \n",
    "                # 5 times per epoch get a rough idea of how the train and test accuracies perform on the test and train\n",
    "                # batches.\n",
    "                if i% freq ==0 or i == (n_batches):\n",
    "                    print(\"Trained {} batches with current epoch cost: {}\".format(i+1,epoch_loss))\n",
    "                    acc_train = sess.run(accuracy,feed_dict = {x: epoch_x, y: epoch_y})\n",
    "                    acc_test = accuracy.eval({x: binarize(mnist.test.images[0:batch_size].reshape((-1, 784, 1))), y: mnist.test.labels[0:batch_size]})\n",
    "                    print(\"At batch: {0}, the training accuracy is: {1:.1%}\".format(i+1, acc_train))\n",
    "                    print(\"At batch: {0}, the test accuracy is: {1:.1%}\".format(i+1, acc_test))\n",
    "                    print(\"Current run time is: {} \\n\".format(time.time()-start_epoch))\n",
    "            saver.save(sess= sess, save_path = save_model)  \n",
    "            # At the end of the epoch calculate the accuracy\n",
    "            if epoch % freq_epoch==0:\n",
    "                print('Epoch', epoch+1, 'completed out of:',hm_epochs,'loss:',epoch_loss, ', time:', time.time()-start,'\\n')\n",
    "                acc_test = accuracy.eval({x: binarize(mnist.test.images[0:batch_size].reshape((-1, 784, 1))), y: mnist.test.labels[0:batch_size]})\n",
    "                print(\"At end of epoch: {0}, the training accuracy on batch is: {1:.1%}\".format(epoch+1, acc_train))\n",
    "                print(\"At end of epoch: {}, the test accuracy is: {:.1%}\".format(epoch+1, acc_test))\n",
    "                acc_list.append(acc_test)\n",
    "                \n",
    "                # If the accuracy is good save model\n",
    "                if epoch>=0:\n",
    "                    if acc_list[count]>= 0.79:\n",
    "                        saver2.save(sess= sess, save_path = save_model2)\n",
    "                        print(acc_list)\n",
    "                print(\"Total time taken for current epoch : {:f} \\n\".format(time.time()-start))\n",
    "            count+=1\n",
    "            \n",
    "            \n",
    "        saver.save(sess= sess, save_path = save_model)\n",
    "        Final_acc_test,Final_cost_test = sess.run([accuracy,cost],feed_dict = {x: binarize(mnist.test.images.reshape((-1, 784, 1))), y: mnist.test.labels})\n",
    "\n",
    "        print(\"At final epoch: {}, the test accuracy is: {:.1%}, with cost {}\".format(epoch+1, Final_acc_test, Final_cost_test))\n",
    "    print(\"Total time taken for run : {:f}\".format(time.time()-start_epoch))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Running Epoch:1-------\n",
      "Trained 1 batches with current epoch cost: 6.807658672332764\n",
      "At batch: 1, the training accuracy is: 10.2%\n",
      "At batch: 1, the test accuracy is: 7.8%\n",
      "Current run time is: 7.168596506118774 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 208.3292280435562\n",
      "At batch: 86, the training accuracy is: 32.0%\n",
      "At batch: 86, the test accuracy is: 34.4%\n",
      "Current run time is: 497.8830535411835 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 346.1216866970062\n",
      "At batch: 171, the training accuracy is: 46.9%\n",
      "At batch: 171, the test accuracy is: 41.4%\n",
      "Current run time is: 907.4758248329163 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 468.2370562553406\n",
      "At batch: 256, the training accuracy is: 50.0%\n",
      "At batch: 256, the test accuracy is: 46.9%\n",
      "Current run time is: 1307.200944185257 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 589.1174758672714\n",
      "At batch: 341, the training accuracy is: 47.7%\n",
      "At batch: 341, the test accuracy is: 43.8%\n",
      "Current run time is: 1716.9596574306488 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 707.0192493200302\n",
      "At batch: 426, the training accuracy is: 48.4%\n",
      "At batch: 426, the test accuracy is: 44.5%\n",
      "Current run time is: 2140.7447731494904 \n",
      "\n",
      "Epoch 1 completed out of: 30 loss: 711.116202235 , time: 2156.0027980804443 \n",
      "\n",
      "At end of epoch: 1, the training accuracy on batch is: 48.4%\n",
      "At end of epoch: 1, the test accuracy is: 49.2%\n",
      "Total time taken for current epoch : 2157.427881 \n",
      "\n",
      "-------Running Epoch:2-------\n",
      "Trained 1 batches with current epoch cost: 1.4108326435089111\n",
      "At batch: 1, the training accuracy is: 45.3%\n",
      "At batch: 1, the test accuracy is: 44.5%\n",
      "Current run time is: 2166.0142834186554 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 118.73619508743286\n",
      "At batch: 86, the training accuracy is: 39.8%\n",
      "At batch: 86, the test accuracy is: 43.0%\n",
      "Current run time is: 2597.1306989192963 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 233.50149834156036\n",
      "At batch: 171, the training accuracy is: 47.7%\n",
      "At batch: 171, the test accuracy is: 47.7%\n",
      "Current run time is: 3018.70982503891 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 347.54126024246216\n",
      "At batch: 256, the training accuracy is: 57.8%\n",
      "At batch: 256, the test accuracy is: 53.1%\n",
      "Current run time is: 3433.728402853012 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 456.4705317020416\n",
      "At batch: 341, the training accuracy is: 54.7%\n",
      "At batch: 341, the test accuracy is: 46.1%\n",
      "Current run time is: 3840.0056505203247 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 566.6814935207367\n",
      "At batch: 426, the training accuracy is: 53.1%\n",
      "At batch: 426, the test accuracy is: 44.5%\n",
      "Current run time is: 4247.2286105155945 \n",
      "\n",
      "Epoch 2 completed out of: 30 loss: 570.073433757 , time: 2104.0081923007965 \n",
      "\n",
      "At end of epoch: 2, the training accuracy on batch is: 53.1%\n",
      "At end of epoch: 2, the test accuracy is: 50.8%\n",
      "Total time taken for current epoch : 2105.341215 \n",
      "\n",
      "-------Running Epoch:3-------\n",
      "Trained 1 batches with current epoch cost: 1.4228341579437256\n",
      "At batch: 1, the training accuracy is: 50.8%\n",
      "At batch: 1, the test accuracy is: 50.8%\n",
      "Current run time is: 4270.322460412979 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 108.34848487377167\n",
      "At batch: 86, the training accuracy is: 55.5%\n",
      "At batch: 86, the test accuracy is: 54.7%\n",
      "Current run time is: 4669.836781024933 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 211.06321114301682\n",
      "At batch: 171, the training accuracy is: 49.2%\n",
      "At batch: 171, the test accuracy is: 53.1%\n",
      "Current run time is: 5073.241108417511 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 310.56240344047546\n",
      "At batch: 256, the training accuracy is: 55.5%\n",
      "At batch: 256, the test accuracy is: 57.0%\n",
      "Current run time is: 5463.334020853043 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 408.1605495810509\n",
      "At batch: 341, the training accuracy is: 57.8%\n",
      "At batch: 341, the test accuracy is: 53.1%\n",
      "Current run time is: 5848.62638425827 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 506.68525689840317\n",
      "At batch: 426, the training accuracy is: 62.5%\n",
      "At batch: 426, the test accuracy is: 59.4%\n",
      "Current run time is: 6237.4810473918915 \n",
      "\n",
      "Epoch 3 completed out of: 30 loss: 509.91657567 , time: 1989.9192187786102 \n",
      "\n",
      "At end of epoch: 3, the training accuracy on batch is: 62.5%\n",
      "At end of epoch: 3, the test accuracy is: 60.2%\n",
      "Total time taken for current epoch : 1991.420561 \n",
      "\n",
      "-------Running Epoch:4-------\n",
      "Trained 1 batches with current epoch cost: 1.0698792934417725\n",
      "At batch: 1, the training accuracy is: 58.6%\n",
      "At batch: 1, the test accuracy is: 59.4%\n",
      "Current run time is: 6262.244518995285 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 90.6086448431015\n",
      "At batch: 86, the training accuracy is: 65.6%\n",
      "At batch: 86, the test accuracy is: 64.1%\n",
      "Current run time is: 6651.480840921402 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 178.46904677152634\n",
      "At batch: 171, the training accuracy is: 70.3%\n",
      "At batch: 171, the test accuracy is: 68.0%\n",
      "Current run time is: 7033.932723999023 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 258.55004185438156\n",
      "At batch: 256, the training accuracy is: 68.0%\n",
      "At batch: 256, the test accuracy is: 68.0%\n",
      "Current run time is: 7419.499764204025 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 344.7432060241699\n",
      "At batch: 341, the training accuracy is: 75.0%\n",
      "At batch: 341, the test accuracy is: 71.9%\n",
      "Current run time is: 7806.643559455872 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 419.19160157442093\n",
      "At batch: 426, the training accuracy is: 71.1%\n",
      "At batch: 426, the test accuracy is: 71.1%\n",
      "Current run time is: 8198.061038732529 \n",
      "\n",
      "Epoch 4 completed out of: 30 loss: 421.608068109 , time: 1958.2648904323578 \n",
      "\n",
      "At end of epoch: 4, the training accuracy on batch is: 71.1%\n",
      "At end of epoch: 4, the test accuracy is: 71.1%\n",
      "Total time taken for current epoch : 1959.629497 \n",
      "\n",
      "-------Running Epoch:5-------\n",
      "Trained 1 batches with current epoch cost: 0.7034614086151123\n",
      "At batch: 1, the training accuracy is: 74.2%\n",
      "At batch: 1, the test accuracy is: 71.9%\n",
      "Current run time is: 8221.52696609497 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 71.39477133750916\n",
      "At batch: 86, the training accuracy is: 72.7%\n",
      "At batch: 86, the test accuracy is: 74.2%\n",
      "Current run time is: 8607.954587936401 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 140.90012603998184\n",
      "At batch: 171, the training accuracy is: 73.4%\n",
      "At batch: 171, the test accuracy is: 71.1%\n",
      "Current run time is: 8992.280176401138 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 212.05683946609497\n",
      "At batch: 256, the training accuracy is: 77.3%\n",
      "At batch: 256, the test accuracy is: 69.5%\n",
      "Current run time is: 9373.932961463928 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 284.9905027747154\n",
      "At batch: 341, the training accuracy is: 69.5%\n",
      "At batch: 341, the test accuracy is: 71.9%\n",
      "Current run time is: 9753.377551555634 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 350.8945422768593\n",
      "At batch: 426, the training accuracy is: 75.8%\n",
      "At batch: 426, the test accuracy is: 73.4%\n",
      "Current run time is: 10139.85558795929 \n",
      "\n",
      "Epoch 5 completed out of: 30 loss: 352.858017266 , time: 1940.7367074489594 \n",
      "\n",
      "At end of epoch: 5, the training accuracy on batch is: 75.8%\n",
      "At end of epoch: 5, the test accuracy is: 71.1%\n",
      "Total time taken for current epoch : 1942.049059 \n",
      "\n",
      "-------Running Epoch:6-------\n",
      "Trained 1 batches with current epoch cost: 0.6577964425086975\n",
      "At batch: 1, the training accuracy is: 78.1%\n",
      "At batch: 1, the test accuracy is: 72.7%\n",
      "Current run time is: 10162.624088287354 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 69.84046989679337\n",
      "At batch: 86, the training accuracy is: 71.9%\n",
      "At batch: 86, the test accuracy is: 71.9%\n",
      "Current run time is: 10545.50823378563 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 133.49096548557281\n",
      "At batch: 171, the training accuracy is: 71.1%\n",
      "At batch: 171, the test accuracy is: 70.3%\n",
      "Current run time is: 10928.288508176804 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 203.2352573275566\n",
      "At batch: 256, the training accuracy is: 75.8%\n",
      "At batch: 256, the test accuracy is: 71.1%\n",
      "Current run time is: 11313.756917476654 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 268.13364988565445\n",
      "At batch: 341, the training accuracy is: 73.4%\n",
      "At batch: 341, the test accuracy is: 76.6%\n",
      "Current run time is: 11694.569295406342 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 326.8462923467159\n",
      "At batch: 426, the training accuracy is: 79.7%\n",
      "At batch: 426, the test accuracy is: 75.8%\n",
      "Current run time is: 12074.489078760147 \n",
      "\n",
      "Epoch 6 completed out of: 30 loss: 329.115338892 , time: 1932.1358730793 \n",
      "\n",
      "At end of epoch: 6, the training accuracy on batch is: 79.7%\n",
      "At end of epoch: 6, the test accuracy is: 68.0%\n",
      "Total time taken for current epoch : 1933.447891 \n",
      "\n",
      "-------Running Epoch:7-------\n",
      "Trained 1 batches with current epoch cost: 0.7468435764312744\n",
      "At batch: 1, the training accuracy is: 74.2%\n",
      "At batch: 1, the test accuracy is: 70.3%\n",
      "Current run time is: 12096.041722536087 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 62.601026475429535\n",
      "At batch: 86, the training accuracy is: 78.9%\n",
      "At batch: 86, the test accuracy is: 74.2%\n",
      "Current run time is: 12474.251302957535 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 119.60203862190247\n",
      "At batch: 171, the training accuracy is: 85.2%\n",
      "At batch: 171, the test accuracy is: 74.2%\n",
      "Current run time is: 12856.48616194725 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 176.51711517572403\n",
      "At batch: 256, the training accuracy is: 76.6%\n",
      "At batch: 256, the test accuracy is: 79.7%\n",
      "Current run time is: 13236.16500043869 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 238.5461356639862\n",
      "At batch: 341, the training accuracy is: 74.2%\n",
      "At batch: 341, the test accuracy is: 75.0%\n",
      "Current run time is: 13613.27160024643 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 299.9499453008175\n",
      "At batch: 426, the training accuracy is: 80.5%\n",
      "At batch: 426, the test accuracy is: 78.1%\n",
      "Current run time is: 13991.422935009003 \n",
      "\n",
      "Epoch 7 completed out of: 30 loss: 301.872871965 , time: 1915.880321264267 \n",
      "\n",
      "At end of epoch: 7, the training accuracy on batch is: 80.5%\n",
      "At end of epoch: 7, the test accuracy is: 78.1%\n",
      "Total time taken for current epoch : 1917.148202 \n",
      "\n",
      "-------Running Epoch:8-------\n",
      "Trained 1 batches with current epoch cost: 0.5207103490829468\n",
      "At batch: 1, the training accuracy is: 81.2%\n",
      "At batch: 1, the test accuracy is: 78.9%\n",
      "Current run time is: 14013.9088742733 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 80.03731161355972\n",
      "At batch: 86, the training accuracy is: 59.4%\n",
      "At batch: 86, the test accuracy is: 62.5%\n",
      "Current run time is: 14390.176434516907 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 156.64745408296585\n",
      "At batch: 171, the training accuracy is: 64.8%\n",
      "At batch: 171, the test accuracy is: 68.0%\n",
      "Current run time is: 14770.511124372482 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 229.26439958810806\n",
      "At batch: 256, the training accuracy is: 58.6%\n",
      "At batch: 256, the test accuracy is: 62.5%\n",
      "Current run time is: 15145.565544366837 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 298.21777898073196\n",
      "At batch: 341, the training accuracy is: 72.7%\n",
      "At batch: 341, the test accuracy is: 77.3%\n",
      "Current run time is: 15519.675142288208 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 359.1582846045494\n",
      "At batch: 426, the training accuracy is: 75.8%\n",
      "At batch: 426, the test accuracy is: 79.7%\n",
      "Current run time is: 15898.751321554184 \n",
      "\n",
      "Epoch 8 completed out of: 30 loss: 361.365971327 , time: 1905.6650755405426 \n",
      "\n",
      "At end of epoch: 8, the training accuracy on batch is: 75.8%\n",
      "At end of epoch: 8, the test accuracy is: 77.3%\n",
      "Total time taken for current epoch : 1906.947564 \n",
      "\n",
      "-------Running Epoch:9-------\n",
      "Trained 1 batches with current epoch cost: 0.9238259792327881\n",
      "At batch: 1, the training accuracy is: 71.1%\n",
      "At batch: 1, the test accuracy is: 71.9%\n",
      "Current run time is: 15920.79005599022 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 61.277774304151535\n",
      "At batch: 86, the training accuracy is: 64.8%\n",
      "At batch: 86, the test accuracy is: 64.1%\n",
      "Current run time is: 16295.091132164001 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 125.2249645292759\n",
      "At batch: 171, the training accuracy is: 67.2%\n",
      "At batch: 171, the test accuracy is: 71.9%\n",
      "Current run time is: 16661.911084890366 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 182.9768154323101\n",
      "At batch: 256, the training accuracy is: 77.3%\n",
      "At batch: 256, the test accuracy is: 77.3%\n",
      "Current run time is: 17036.637376070023 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 237.6608655154705\n",
      "At batch: 341, the training accuracy is: 80.5%\n",
      "At batch: 341, the test accuracy is: 78.9%\n",
      "Current run time is: 17412.903831481934 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 300.7174392044544\n",
      "At batch: 426, the training accuracy is: 80.5%\n",
      "At batch: 426, the test accuracy is: 75.0%\n",
      "Current run time is: 17790.93262863159 \n",
      "\n",
      "Epoch 9 completed out of: 30 loss: 302.567469209 , time: 1892.8121495246887 \n",
      "\n",
      "At end of epoch: 9, the training accuracy on batch is: 80.5%\n",
      "At end of epoch: 9, the test accuracy is: 75.0%\n",
      "Total time taken for current epoch : 1894.241330 \n",
      "\n",
      "-------Running Epoch:10-------\n",
      "Trained 1 batches with current epoch cost: 0.8696153163909912\n",
      "At batch: 1, the training accuracy is: 73.4%\n",
      "At batch: 1, the test accuracy is: 76.6%\n",
      "Current run time is: 17815.126326560974 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 62.79110383987427\n",
      "At batch: 86, the training accuracy is: 78.9%\n",
      "At batch: 86, the test accuracy is: 71.9%\n",
      "Current run time is: 18191.98822903633 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 118.84238657355309\n",
      "At batch: 171, the training accuracy is: 82.0%\n",
      "At batch: 171, the test accuracy is: 77.3%\n",
      "Current run time is: 18570.713309764862 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 170.3008904159069\n",
      "At batch: 256, the training accuracy is: 83.6%\n",
      "At batch: 256, the test accuracy is: 78.1%\n",
      "Current run time is: 18941.790442228317 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 220.91123494505882\n",
      "At batch: 341, the training accuracy is: 78.1%\n",
      "At batch: 341, the test accuracy is: 73.4%\n",
      "Current run time is: 19316.727870941162 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 274.4166944026947\n",
      "At batch: 426, the training accuracy is: 76.6%\n",
      "At batch: 426, the test accuracy is: 70.3%\n",
      "Current run time is: 19688.997309684753 \n",
      "\n",
      "Epoch 10 completed out of: 30 loss: 276.229015231 , time: 1896.0384995937347 \n",
      "\n",
      "At end of epoch: 10, the training accuracy on batch is: 76.6%\n",
      "At end of epoch: 10, the test accuracy is: 73.4%\n",
      "Total time taken for current epoch : 1897.316594 \n",
      "\n",
      "-------Running Epoch:11-------\n",
      "Trained 1 batches with current epoch cost: 0.6604032516479492\n",
      "At batch: 1, the training accuracy is: 76.6%\n",
      "At batch: 1, the test accuracy is: 73.4%\n",
      "Current run time is: 19712.591546535492 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 49.991538256406784\n",
      "At batch: 86, the training accuracy is: 82.8%\n",
      "At batch: 86, the test accuracy is: 77.3%\n",
      "Current run time is: 20083.912436008453 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 102.85554495453835\n",
      "At batch: 171, the training accuracy is: 68.0%\n",
      "At batch: 171, the test accuracy is: 75.0%\n",
      "Current run time is: 20454.046907663345 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 156.12379869818687\n",
      "At batch: 256, the training accuracy is: 80.5%\n",
      "At batch: 256, the test accuracy is: 75.8%\n",
      "Current run time is: 20833.798580169678 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 208.24035108089447\n",
      "At batch: 341, the training accuracy is: 76.6%\n",
      "At batch: 341, the test accuracy is: 77.3%\n",
      "Current run time is: 21229.411836624146 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 259.74617198109627\n",
      "At batch: 426, the training accuracy is: 76.6%\n",
      "At batch: 426, the test accuracy is: 74.2%\n",
      "Current run time is: 21610.534648180008 \n",
      "\n",
      "Epoch 11 completed out of: 30 loss: 261.455871135 , time: 1919.7238357067108 \n",
      "\n",
      "At end of epoch: 11, the training accuracy on batch is: 76.6%\n",
      "At end of epoch: 11, the test accuracy is: 78.1%\n",
      "Total time taken for current epoch : 1921.065925 \n",
      "\n",
      "-------Running Epoch:12-------\n",
      "Trained 1 batches with current epoch cost: 0.4847347140312195\n",
      "At batch: 1, the training accuracy is: 83.6%\n",
      "At batch: 1, the test accuracy is: 77.3%\n",
      "Current run time is: 21632.527572393417 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 49.67269530892372\n",
      "At batch: 86, the training accuracy is: 81.2%\n",
      "At batch: 86, the test accuracy is: 78.1%\n",
      "Current run time is: 22025.876420259476 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 117.41668453812599\n",
      "At batch: 171, the training accuracy is: 71.9%\n",
      "At batch: 171, the test accuracy is: 73.4%\n",
      "Current run time is: 22401.293567180634 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 176.41815862059593\n",
      "At batch: 256, the training accuracy is: 68.8%\n",
      "At batch: 256, the test accuracy is: 68.8%\n",
      "Current run time is: 22783.788524627686 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 252.98703971505165\n",
      "At batch: 341, the training accuracy is: 71.1%\n",
      "At batch: 341, the test accuracy is: 73.4%\n",
      "Current run time is: 23165.07531285286 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 308.5877730548382\n",
      "At batch: 426, the training accuracy is: 82.0%\n",
      "At batch: 426, the test accuracy is: 80.5%\n",
      "Current run time is: 23549.305995464325 \n",
      "\n",
      "Epoch 12 completed out of: 30 loss: 311.032898694 , time: 1937.3847947120667 \n",
      "\n",
      "At end of epoch: 12, the training accuracy on batch is: 82.0%\n",
      "At end of epoch: 12, the test accuracy is: 75.8%\n",
      "Total time taken for current epoch : 1938.718535 \n",
      "\n",
      "-------Running Epoch:13-------\n",
      "Trained 1 batches with current epoch cost: 0.6197067499160767\n",
      "At batch: 1, the training accuracy is: 75.8%\n",
      "At batch: 1, the test accuracy is: 77.3%\n",
      "Current run time is: 23571.749146938324 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 52.58141079545021\n",
      "At batch: 86, the training accuracy is: 83.6%\n",
      "At batch: 86, the test accuracy is: 78.1%\n",
      "Current run time is: 23952.965973615646 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 101.57611417770386\n",
      "At batch: 171, the training accuracy is: 75.0%\n",
      "At batch: 171, the test accuracy is: 71.9%\n",
      "Current run time is: 24330.15919303894 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 149.13042476773262\n",
      "At batch: 256, the training accuracy is: 82.8%\n",
      "At batch: 256, the test accuracy is: 78.9%\n",
      "Current run time is: 24712.13711643219 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 198.2471488714218\n",
      "At batch: 341, the training accuracy is: 79.7%\n",
      "At batch: 341, the test accuracy is: 75.8%\n",
      "Current run time is: 25090.82380795479 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 258.08949053287506\n",
      "At batch: 426, the training accuracy is: 85.2%\n",
      "At batch: 426, the test accuracy is: 82.8%\n",
      "Current run time is: 25476.152885198593 \n",
      "\n",
      "Epoch 13 completed out of: 30 loss: 259.765286654 , time: 1925.4974076747894 \n",
      "\n",
      "At end of epoch: 13, the training accuracy on batch is: 85.2%\n",
      "At end of epoch: 13, the test accuracy is: 84.4%\n",
      "[0.4921875, 0.5078125, 0.6015625, 0.7109375, 0.7109375, 0.6796875, 0.78125, 0.7734375, 0.75, 0.734375, 0.78125, 0.7578125, 0.84375]\n",
      "Total time taken for current epoch : 1927.248930 \n",
      "\n",
      "-------Running Epoch:14-------\n",
      "Trained 1 batches with current epoch cost: 0.6188726425170898\n",
      "At batch: 1, the training accuracy is: 80.5%\n",
      "At batch: 1, the test accuracy is: 80.5%\n",
      "Current run time is: 25499.11833834648 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 49.8693020939827\n",
      "At batch: 86, the training accuracy is: 78.9%\n",
      "At batch: 86, the test accuracy is: 70.3%\n",
      "Current run time is: 25879.916065454483 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 105.09050953388214\n",
      "At batch: 171, the training accuracy is: 82.8%\n",
      "At batch: 171, the test accuracy is: 76.6%\n",
      "Current run time is: 26264.994848251343 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 150.71372297406197\n",
      "At batch: 256, the training accuracy is: 83.6%\n",
      "At batch: 256, the test accuracy is: 75.8%\n",
      "Current run time is: 26645.106647968292 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 205.94385433197021\n",
      "At batch: 341, the training accuracy is: 78.9%\n",
      "At batch: 341, the test accuracy is: 82.0%\n",
      "Current run time is: 27020.259105682373 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 299.2103039622307\n",
      "At batch: 426, the training accuracy is: 66.4%\n",
      "At batch: 426, the test accuracy is: 60.2%\n",
      "Current run time is: 27410.649942159653 \n",
      "\n",
      "Epoch 14 completed out of: 30 loss: 302.057386696 , time: 1932.016364812851 \n",
      "\n",
      "At end of epoch: 14, the training accuracy on batch is: 66.4%\n",
      "At end of epoch: 14, the test accuracy is: 55.5%\n",
      "Total time taken for current epoch : 1933.280464 \n",
      "\n",
      "-------Running Epoch:15-------\n",
      "Trained 1 batches with current epoch cost: 0.9851217269897461\n",
      "At batch: 1, the training accuracy is: 64.8%\n",
      "At batch: 1, the test accuracy is: 57.8%\n",
      "Current run time is: 27432.8897087574 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 101.70761156082153\n",
      "At batch: 86, the training accuracy is: 45.3%\n",
      "At batch: 86, the test accuracy is: 48.4%\n",
      "Current run time is: 27806.863990545273 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 189.78714603185654\n",
      "At batch: 171, the training accuracy is: 67.2%\n",
      "At batch: 171, the test accuracy is: 68.0%\n",
      "Current run time is: 28191.595965623856 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 251.81621223688126\n",
      "At batch: 256, the training accuracy is: 71.9%\n",
      "At batch: 256, the test accuracy is: 71.1%\n",
      "Current run time is: 28579.929461479187 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 309.2935916483402\n",
      "At batch: 341, the training accuracy is: 82.8%\n",
      "At batch: 341, the test accuracy is: 79.7%\n",
      "Current run time is: 28955.435804128647 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 360.6471900045872\n",
      "At batch: 426, the training accuracy is: 78.9%\n",
      "At batch: 426, the test accuracy is: 79.7%\n",
      "Current run time is: 29334.10604405403 \n",
      "\n",
      "Epoch 15 completed out of: 30 loss: 362.513695449 , time: 1923.0555574893951 \n",
      "\n",
      "At end of epoch: 15, the training accuracy on batch is: 78.9%\n",
      "At end of epoch: 15, the test accuracy is: 76.6%\n",
      "Total time taken for current epoch : 1924.501114 \n",
      "\n",
      "-------Running Epoch:16-------\n",
      "Trained 1 batches with current epoch cost: 0.6696345806121826\n",
      "At batch: 1, the training accuracy is: 75.8%\n",
      "At batch: 1, the test accuracy is: 75.8%\n",
      "Current run time is: 29357.264281749725 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 54.742799907922745\n",
      "At batch: 86, the training accuracy is: 77.3%\n",
      "At batch: 86, the test accuracy is: 75.8%\n",
      "Current run time is: 29731.83136534691 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 102.97304198145866\n",
      "At batch: 171, the training accuracy is: 73.4%\n",
      "At batch: 171, the test accuracy is: 78.1%\n",
      "Current run time is: 30119.411537885666 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 152.20204639434814\n",
      "At batch: 256, the training accuracy is: 77.3%\n",
      "At batch: 256, the test accuracy is: 78.1%\n",
      "Current run time is: 30496.461812019348 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 199.3024337887764\n",
      "At batch: 341, the training accuracy is: 82.0%\n",
      "At batch: 341, the test accuracy is: 76.6%\n",
      "Current run time is: 30882.709501743317 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 299.07967019081116\n",
      "At batch: 426, the training accuracy is: 65.6%\n",
      "At batch: 426, the test accuracy is: 64.1%\n",
      "Current run time is: 31269.05448293686 \n",
      "\n",
      "Epoch 16 completed out of: 30 loss: 302.223522365 , time: 1933.6750543117523 \n",
      "\n",
      "At end of epoch: 16, the training accuracy on batch is: 65.6%\n",
      "At end of epoch: 16, the test accuracy is: 67.2%\n",
      "Total time taken for current epoch : 1935.009338 \n",
      "\n",
      "-------Running Epoch:17-------\n",
      "Trained 1 batches with current epoch cost: 0.9595361948013306\n",
      "At batch: 1, the training accuracy is: 64.1%\n",
      "At batch: 1, the test accuracy is: 68.0%\n",
      "Current run time is: 31291.89700961113 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 67.546191573143\n",
      "At batch: 86, the training accuracy is: 68.0%\n",
      "At batch: 86, the test accuracy is: 75.8%\n",
      "Current run time is: 31675.928273916245 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 121.25730639696121\n",
      "At batch: 171, the training accuracy is: 79.7%\n",
      "At batch: 171, the test accuracy is: 76.6%\n",
      "Current run time is: 32057.74171090126 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 170.85918346047401\n",
      "At batch: 256, the training accuracy is: 83.6%\n",
      "At batch: 256, the test accuracy is: 80.5%\n",
      "Current run time is: 32439.638311624527 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 221.55444538593292\n",
      "At batch: 341, the training accuracy is: 83.6%\n",
      "At batch: 341, the test accuracy is: 82.0%\n",
      "Current run time is: 32811.81458425522 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 270.16896373033524\n",
      "At batch: 426, the training accuracy is: 77.3%\n",
      "At batch: 426, the test accuracy is: 80.5%\n",
      "Current run time is: 33182.71740627289 \n",
      "\n",
      "Epoch 17 completed out of: 30 loss: 271.91541177 , time: 1911.1842164993286 \n",
      "\n",
      "At end of epoch: 17, the training accuracy on batch is: 77.3%\n",
      "At end of epoch: 17, the test accuracy is: 79.7%\n",
      "[0.4921875, 0.5078125, 0.6015625, 0.7109375, 0.7109375, 0.6796875, 0.78125, 0.7734375, 0.75, 0.734375, 0.78125, 0.7578125, 0.84375, 0.5546875, 0.765625, 0.671875, 0.796875]\n",
      "Total time taken for current epoch : 1912.937973 \n",
      "\n",
      "-------Running Epoch:18-------\n",
      "Trained 1 batches with current epoch cost: 0.46785444021224976\n",
      "At batch: 1, the training accuracy is: 84.4%\n",
      "At batch: 1, the test accuracy is: 80.5%\n",
      "Current run time is: 33205.88460969925 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 48.71063303947449\n",
      "At batch: 86, the training accuracy is: 81.2%\n",
      "At batch: 86, the test accuracy is: 83.6%\n",
      "Current run time is: 33588.58570384979 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 97.29022091627121\n",
      "At batch: 171, the training accuracy is: 78.1%\n",
      "At batch: 171, the test accuracy is: 78.1%\n",
      "Current run time is: 33970.51635527611 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 143.08819299936295\n",
      "At batch: 256, the training accuracy is: 85.9%\n",
      "At batch: 256, the test accuracy is: 85.2%\n",
      "Current run time is: 34356.39180970192 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 186.2681523859501\n",
      "At batch: 341, the training accuracy is: 83.6%\n",
      "At batch: 341, the test accuracy is: 83.6%\n",
      "Current run time is: 34737.01365542412 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 229.82641905546188\n",
      "At batch: 426, the training accuracy is: 80.5%\n",
      "At batch: 426, the test accuracy is: 83.6%\n",
      "Current run time is: 35124.174765110016 \n",
      "\n",
      "Epoch 18 completed out of: 30 loss: 231.500017345 , time: 1940.4906849861145 \n",
      "\n",
      "At end of epoch: 18, the training accuracy on batch is: 80.5%\n",
      "At end of epoch: 18, the test accuracy is: 82.0%\n",
      "[0.4921875, 0.5078125, 0.6015625, 0.7109375, 0.7109375, 0.6796875, 0.78125, 0.7734375, 0.75, 0.734375, 0.78125, 0.7578125, 0.84375, 0.5546875, 0.765625, 0.671875, 0.796875, 0.8203125]\n",
      "Total time taken for current epoch : 1942.352028 \n",
      "\n",
      "-------Running Epoch:19-------\n",
      "Trained 1 batches with current epoch cost: 0.3209071755409241\n",
      "At batch: 1, the training accuracy is: 90.6%\n",
      "At batch: 1, the test accuracy is: 81.2%\n",
      "Current run time is: 35148.006680727005 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 46.080254435539246\n",
      "At batch: 86, the training accuracy is: 82.0%\n",
      "At batch: 86, the test accuracy is: 80.5%\n",
      "Current run time is: 35529.45089864731 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 93.48228535056114\n",
      "At batch: 171, the training accuracy is: 85.2%\n",
      "At batch: 171, the test accuracy is: 80.5%\n",
      "Current run time is: 35904.980483055115 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 135.7105724811554\n",
      "At batch: 256, the training accuracy is: 87.5%\n",
      "At batch: 256, the test accuracy is: 84.4%\n",
      "Current run time is: 36287.32710194588 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 178.22669529914856\n",
      "At batch: 341, the training accuracy is: 82.8%\n",
      "At batch: 341, the test accuracy is: 88.3%\n",
      "Current run time is: 36668.37669253349 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 221.8381271660328\n",
      "At batch: 426, the training accuracy is: 83.6%\n",
      "At batch: 426, the test accuracy is: 80.5%\n",
      "Current run time is: 37048.86269760132 \n",
      "\n",
      "Epoch 19 completed out of: 30 loss: 223.270087034 , time: 1922.9960489273071 \n",
      "\n",
      "At end of epoch: 19, the training accuracy on batch is: 83.6%\n",
      "At end of epoch: 19, the test accuracy is: 83.6%\n",
      "[0.4921875, 0.5078125, 0.6015625, 0.7109375, 0.7109375, 0.6796875, 0.78125, 0.7734375, 0.75, 0.734375, 0.78125, 0.7578125, 0.84375, 0.5546875, 0.765625, 0.671875, 0.796875, 0.8203125, 0.8359375]\n",
      "Total time taken for current epoch : 1924.726593 \n",
      "\n",
      "-------Running Epoch:20-------\n",
      "Trained 1 batches with current epoch cost: 0.4683283567428589\n",
      "At batch: 1, the training accuracy is: 85.9%\n",
      "At batch: 1, the test accuracy is: 82.0%\n",
      "Current run time is: 37072.02717089653 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 40.52275490760803\n",
      "At batch: 86, the training accuracy is: 89.1%\n",
      "At batch: 86, the test accuracy is: 85.2%\n",
      "Current run time is: 37453.36026954651 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 82.933633685112\n",
      "At batch: 171, the training accuracy is: 80.5%\n",
      "At batch: 171, the test accuracy is: 85.2%\n",
      "Current run time is: 37828.031416893005 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 125.51123002171516\n",
      "At batch: 256, the training accuracy is: 85.9%\n",
      "At batch: 256, the test accuracy is: 85.2%\n",
      "Current run time is: 38205.941832304 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 297.1016498506069\n",
      "At batch: 341, the training accuracy is: 31.2%\n",
      "At batch: 341, the test accuracy is: 28.1%\n",
      "Current run time is: 40722.31884646416 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 439.66216334700584\n",
      "At batch: 426, the training accuracy is: 35.9%\n",
      "At batch: 426, the test accuracy is: 44.5%\n",
      "Current run time is: 41105.774559259415 \n",
      "\n",
      "Epoch 20 completed out of: 30 loss: 444.231505364 , time: 4054.5842497348785 \n",
      "\n",
      "At end of epoch: 20, the training accuracy on batch is: 35.9%\n",
      "At end of epoch: 20, the test accuracy is: 46.9%\n",
      "Total time taken for current epoch : 4056.218325 \n",
      "\n",
      "-------Running Epoch:21-------\n",
      "Trained 1 batches with current epoch cost: 1.4960432052612305\n",
      "At batch: 1, the training accuracy is: 48.4%\n",
      "At batch: 1, the test accuracy is: 46.1%\n",
      "Current run time is: 41128.12775707245 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0c4011d4ca19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-a928c29d8a71>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(hm_epochs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmerged_summary_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0msummary_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#optimize(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to reload from where it went bad and half the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize2(hm_epochs):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)        \n",
    "        saver2restore = tf.train.Saver()\n",
    "        saver2restore.restore(sess = sess, save_path= save_model2)\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())        \n",
    "        start_epoch = time.time()\n",
    "        freq_epoch = 1\n",
    "        acc_list = [ accuracy.eval({x: binarize(mnist.test.images[0:batch_size].reshape((-1, 784, 1))), y: mnist.test.labels[0:batch_size]})]\n",
    "        count = 1\n",
    "        print(acc_list)\n",
    "        # For each epoch loop over all batches and optimize the cost and produce the test cost\n",
    "        for epoch in range(hm_epochs):\n",
    "            print(\"-------Running Epoch:{}-------\".format(epoch+1))\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            start = time.time()\n",
    "            n_batches = int(mnist.train.num_examples/batch_size)\n",
    "            #n_batches = 10\n",
    "            # print batch test and train costs.            \n",
    "            freq = int(n_batches/5)\n",
    "            for i in range(n_batches):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                epoch_x = binarize(epoch_x)\n",
    "                epoch_x = epoch_x.reshape((batch_size,n_chunks,chunk_size))\n",
    "\n",
    "\n",
    "                _, c,summary = sess.run([optimizer, cost,merged_summary_op], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                summary_writer.add_summary(summary, epoch * n_batches + i)\n",
    "                epoch_loss += c\n",
    "                \n",
    "                # 5 times per epoch get a rough idea of how the train and test accuracies perform on the test and train\n",
    "                # batches.\n",
    "                if i% freq ==0 or i == (n_batches):\n",
    "                    print(\"Trained {} batches with current epoch cost: {}\".format(i+1,epoch_loss))\n",
    "                    acc_train = sess.run(accuracy,feed_dict = {x: epoch_x, y: epoch_y})\n",
    "                    acc_test = accuracy.eval({x: binarize(mnist.test.images[0:batch_size].reshape((-1, 784, 1))), y: mnist.test.labels[0:batch_size]})\n",
    "                    print(\"At batch: {0}, the training accuracy is: {1:.1%}\".format(i+1, acc_train))\n",
    "                    print(\"At batch: {0}, the test accuracy is: {1:.1%}\".format(i+1, acc_test))\n",
    "                    print(\"Current run time is: {} \\n\".format(time.time()-start_epoch))\n",
    "            saver.save(sess= sess, save_path = save_model)  \n",
    "            # At the end of the epoch calculate the accuracy\n",
    "            if epoch % freq_epoch==0:\n",
    "                print('Epoch', epoch+1, 'completed out of:',hm_epochs,'loss:',epoch_loss, ', time:', time.time()-start,'\\n')\n",
    "                acc_test = accuracy.eval({x: binarize(mnist.test.images[0:batch_size].reshape((-1, 784, 1))), y: mnist.test.labels[0:batch_size]})\n",
    "                print(\"At end of epoch: {0}, the training accuracy on batch is: {1:.1%}\".format(epoch+1, acc_train))\n",
    "                print(\"At end of epoch: {}, the test accuracy is: {:.1%}\".format(epoch+1, acc_test))\n",
    "                acc_list.append(acc_test)\n",
    "                \n",
    "                # If the accuracy is good save model\n",
    "                if epoch>=0:\n",
    "                    if acc_list[count]>= 0.82:\n",
    "                        saver3.save(sess= sess, save_path = save_model3)\n",
    "                        print(acc_list)\n",
    "                print(\"Total time taken for current epoch : {:f} \\n\".format(time.time()-start))\n",
    "            count+=1\n",
    "            \n",
    "            \n",
    "        saver.save(sess= sess, save_path = save_model)\n",
    "        Final_acc_test,Final_cost_test = sess.run([accuracy,cost],feed_dict = {x: binarize(mnist.test.images.reshape((-1, 784, 1))), y: mnist.test.labels})\n",
    "\n",
    "        print(\"At final epoch: {}, the test accuracy is: {:.1%}, with cost {}\".format(epoch+1, Final_acc_test, Final_cost_test))\n",
    "    print(\"Total time taken for run : {:f}\".format(time.time()-start_epoch))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to save the model, weights and biases varibles\n",
    "saver3 = tf.train.Saver(write_version = tf.train.SaverDef.V2)\n",
    "\n",
    "# Suggested Directory to use\n",
    "save_MDir3 = 'models/lstm32/best/'\n",
    "\n",
    "\n",
    "#create the directory if it does not exist already\n",
    "if not os.path.exists(save_MDir3):\n",
    "    os.makedirs(save_MDir3)\n",
    "\n",
    "save_model3 = os.path.join(save_MDir3,'best_accuracyE10_LR0_0001_cont')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8359375]\n",
      "-------Running Epoch:1-------\n",
      "Trained 1 batches with current epoch cost: 0.4603498578071594\n",
      "At batch: 1, the training accuracy is: 82.8%\n",
      "At batch: 1, the test accuracy is: 82.8%\n",
      "Current run time is: 7.325735807418823 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 46.16175103187561\n",
      "At batch: 86, the training accuracy is: 82.8%\n",
      "At batch: 86, the test accuracy is: 89.1%\n",
      "Current run time is: 351.3045346736908 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 88.94161745905876\n",
      "At batch: 171, the training accuracy is: 86.7%\n",
      "At batch: 171, the test accuracy is: 86.7%\n",
      "Current run time is: 689.2883038520813 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 132.10658192634583\n",
      "At batch: 256, the training accuracy is: 85.9%\n",
      "At batch: 256, the test accuracy is: 82.8%\n",
      "Current run time is: 1040.893094778061 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 174.82955268025398\n",
      "At batch: 341, the training accuracy is: 93.0%\n",
      "At batch: 341, the test accuracy is: 84.4%\n",
      "Current run time is: 2642.3621418476105 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 215.02427071332932\n",
      "At batch: 426, the training accuracy is: 89.1%\n",
      "At batch: 426, the test accuracy is: 87.5%\n",
      "Current run time is: 3011.85728764534 \n",
      "\n",
      "Epoch 1 completed out of: 10 loss: 216.258457094 , time: 3025.424654006958 \n",
      "\n",
      "At end of epoch: 1, the training accuracy on batch is: 89.1%\n",
      "At end of epoch: 1, the test accuracy is: 88.3%\n",
      "[0.8359375, 0.8828125]\n",
      "Total time taken for current epoch : 3027.836407 \n",
      "\n",
      "-------Running Epoch:2-------\n",
      "Trained 1 batches with current epoch cost: 0.482796847820282\n",
      "At batch: 1, the training accuracy is: 88.3%\n",
      "At batch: 1, the test accuracy is: 89.1%\n",
      "Current run time is: 3036.088788986206 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 38.29131066799164\n",
      "At batch: 86, the training accuracy is: 92.2%\n",
      "At batch: 86, the test accuracy is: 85.2%\n",
      "Current run time is: 3396.5337228775024 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 75.64347064495087\n",
      "At batch: 171, the training accuracy is: 90.6%\n",
      "At batch: 171, the test accuracy is: 84.4%\n",
      "Current run time is: 3749.2069680690765 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 115.89360222220421\n",
      "At batch: 256, the training accuracy is: 83.6%\n",
      "At batch: 256, the test accuracy is: 85.9%\n",
      "Current run time is: 4141.542526483536 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 156.90825355052948\n",
      "At batch: 341, the training accuracy is: 89.1%\n",
      "At batch: 341, the test accuracy is: 85.2%\n",
      "Current run time is: 4492.291345834732 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 196.2191555649042\n",
      "At batch: 426, the training accuracy is: 90.6%\n",
      "At batch: 426, the test accuracy is: 88.3%\n",
      "Current run time is: 4852.222512483597 \n",
      "\n",
      "Epoch 2 completed out of: 10 loss: 197.809912786 , time: 1837.82812833786 \n",
      "\n",
      "At end of epoch: 2, the training accuracy on batch is: 90.6%\n",
      "At end of epoch: 2, the test accuracy is: 85.9%\n",
      "[0.8359375, 0.8828125, 0.859375]\n",
      "Total time taken for current epoch : 1840.276477 \n",
      "\n",
      "-------Running Epoch:3-------\n",
      "Trained 1 batches with current epoch cost: 0.47724413871765137\n",
      "At batch: 1, the training accuracy is: 85.2%\n",
      "At batch: 1, the test accuracy is: 85.9%\n",
      "Current run time is: 4877.598432540894 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 48.251443922519684\n",
      "At batch: 86, the training accuracy is: 82.0%\n",
      "At batch: 86, the test accuracy is: 79.7%\n",
      "Current run time is: 5231.200352668762 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 93.48197421431541\n",
      "At batch: 171, the training accuracy is: 76.6%\n",
      "At batch: 171, the test accuracy is: 75.8%\n",
      "Current run time is: 5605.541592597961 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 154.09280890226364\n",
      "At batch: 256, the training accuracy is: 75.0%\n",
      "At batch: 256, the test accuracy is: 65.6%\n",
      "Current run time is: 6001.864552736282 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 214.63800555467606\n",
      "At batch: 341, the training accuracy is: 82.0%\n",
      "At batch: 341, the test accuracy is: 84.4%\n",
      "Current run time is: 6394.573178529739 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 270.8604105710983\n",
      "At batch: 426, the training accuracy is: 78.9%\n",
      "At batch: 426, the test accuracy is: 83.6%\n",
      "Current run time is: 6786.40477514267 \n",
      "\n",
      "Epoch 3 completed out of: 10 loss: 272.881036222 , time: 1932.3520274162292 \n",
      "\n",
      "At end of epoch: 3, the training accuracy on batch is: 78.9%\n",
      "At end of epoch: 3, the test accuracy is: 81.2%\n",
      "Total time taken for current epoch : 1933.738486 \n",
      "\n",
      "-------Running Epoch:4-------\n",
      "Trained 1 batches with current epoch cost: 0.6022101640701294\n",
      "At batch: 1, the training accuracy is: 81.2%\n",
      "At batch: 1, the test accuracy is: 79.7%\n",
      "Current run time is: 6811.44646859169 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 75.6564105451107\n",
      "At batch: 86, the training accuracy is: 80.5%\n",
      "At batch: 86, the test accuracy is: 75.0%\n",
      "Current run time is: 7220.385631322861 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 132.20112717151642\n",
      "At batch: 171, the training accuracy is: 78.9%\n",
      "At batch: 171, the test accuracy is: 76.6%\n",
      "Current run time is: 7618.655295372009 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 178.696347117424\n",
      "At batch: 256, the training accuracy is: 89.1%\n",
      "At batch: 256, the test accuracy is: 85.9%\n",
      "Current run time is: 7997.045909643173 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 218.87074741721153\n",
      "At batch: 341, the training accuracy is: 89.1%\n",
      "At batch: 341, the test accuracy is: 85.9%\n",
      "Current run time is: 8345.355189561844 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 258.3294216096401\n",
      "At batch: 426, the training accuracy is: 85.2%\n",
      "At batch: 426, the test accuracy is: 85.9%\n",
      "Current run time is: 8707.890378952026 \n",
      "\n",
      "Epoch 4 completed out of: 10 loss: 259.934713185 , time: 1918.627248287201 \n",
      "\n",
      "At end of epoch: 4, the training accuracy on batch is: 85.2%\n",
      "At end of epoch: 4, the test accuracy is: 82.0%\n",
      "[0.8359375, 0.8828125, 0.859375, 0.8125, 0.8203125]\n",
      "Total time taken for current epoch : 1921.133174 \n",
      "\n",
      "-------Running Epoch:5-------\n",
      "Trained 1 batches with current epoch cost: 0.4720720052719116\n",
      "At batch: 1, the training accuracy is: 85.9%\n",
      "At batch: 1, the test accuracy is: 80.5%\n",
      "Current run time is: 8732.045924425125 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 43.38236507773399\n",
      "At batch: 86, the training accuracy is: 89.1%\n",
      "At batch: 86, the test accuracy is: 87.5%\n",
      "Current run time is: 9101.75784277916 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 81.36476390063763\n",
      "At batch: 171, the training accuracy is: 82.8%\n",
      "At batch: 171, the test accuracy is: 88.3%\n",
      "Current run time is: 9467.998754262924 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 121.28346732258797\n",
      "At batch: 256, the training accuracy is: 82.0%\n",
      "At batch: 256, the test accuracy is: 85.2%\n",
      "Current run time is: 9835.033528089523 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 160.01459541916847\n",
      "At batch: 341, the training accuracy is: 89.1%\n",
      "At batch: 341, the test accuracy is: 89.8%\n",
      "Current run time is: 10218.27710533142 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 199.97348228096962\n",
      "At batch: 426, the training accuracy is: 89.1%\n",
      "At batch: 426, the test accuracy is: 85.2%\n",
      "Current run time is: 12808.202180624008 \n",
      "\n",
      "Epoch 5 completed out of: 10 loss: 201.567020178 , time: 4098.595141172409 \n",
      "\n",
      "At end of epoch: 5, the training accuracy on batch is: 89.1%\n",
      "At end of epoch: 5, the test accuracy is: 84.4%\n",
      "[0.8359375, 0.8828125, 0.859375, 0.8125, 0.8203125, 0.84375]\n",
      "Total time taken for current epoch : 4101.055685 \n",
      "\n",
      "-------Running Epoch:6-------\n",
      "Trained 1 batches with current epoch cost: 0.3615131974220276\n",
      "At batch: 1, the training accuracy is: 89.8%\n",
      "At batch: 1, the test accuracy is: 83.6%\n",
      "Current run time is: 12833.39481639862 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 41.03105339407921\n",
      "At batch: 86, the training accuracy is: 89.1%\n",
      "At batch: 86, the test accuracy is: 85.2%\n",
      "Current run time is: 13184.519792079926 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 80.76285257935524\n",
      "At batch: 171, the training accuracy is: 82.0%\n",
      "At batch: 171, the test accuracy is: 80.5%\n",
      "Current run time is: 13524.23440527916 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 116.63288383185863\n",
      "At batch: 256, the training accuracy is: 88.3%\n",
      "At batch: 256, the test accuracy is: 83.6%\n",
      "Current run time is: 13852.580092191696 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 154.5035069733858\n",
      "At batch: 341, the training accuracy is: 88.3%\n",
      "At batch: 341, the test accuracy is: 89.1%\n",
      "Current run time is: 14190.696675300598 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 190.75717566907406\n",
      "At batch: 426, the training accuracy is: 85.2%\n",
      "At batch: 426, the test accuracy is: 83.6%\n",
      "Current run time is: 14535.565412044525 \n",
      "\n",
      "Epoch 6 completed out of: 10 loss: 192.282053217 , time: 1723.125407218933 \n",
      "\n",
      "At end of epoch: 6, the training accuracy on batch is: 85.2%\n",
      "At end of epoch: 6, the test accuracy is: 85.2%\n",
      "[0.8359375, 0.8828125, 0.859375, 0.8125, 0.8203125, 0.84375, 0.8515625]\n",
      "Total time taken for current epoch : 1725.475677 \n",
      "\n",
      "-------Running Epoch:7-------\n",
      "Trained 1 batches with current epoch cost: 0.4789656400680542\n",
      "At batch: 1, the training accuracy is: 85.2%\n",
      "At batch: 1, the test accuracy is: 83.6%\n",
      "Current run time is: 14557.637698173523 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 39.18691694736481\n",
      "At batch: 86, the training accuracy is: 88.3%\n",
      "At batch: 86, the test accuracy is: 85.2%\n",
      "Current run time is: 14897.297867774963 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 77.88694322109222\n",
      "At batch: 171, the training accuracy is: 85.2%\n",
      "At batch: 171, the test accuracy is: 89.1%\n",
      "Current run time is: 15230.380054473877 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 154.712674587965\n",
      "At batch: 256, the training accuracy is: 80.5%\n",
      "At batch: 256, the test accuracy is: 79.7%\n",
      "Current run time is: 15568.941387414932 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 202.2988144159317\n",
      "At batch: 341, the training accuracy is: 78.9%\n",
      "At batch: 341, the test accuracy is: 85.9%\n",
      "Current run time is: 15923.40184378624 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 241.26573553681374\n",
      "At batch: 426, the training accuracy is: 86.7%\n",
      "At batch: 426, the test accuracy is: 81.2%\n",
      "Current run time is: 16266.1563975811 \n",
      "\n",
      "Epoch 7 completed out of: 10 loss: 242.792227179 , time: 1728.4601845741272 \n",
      "\n",
      "At end of epoch: 7, the training accuracy on batch is: 86.7%\n",
      "At end of epoch: 7, the test accuracy is: 80.5%\n",
      "Total time taken for current epoch : 1729.642531 \n",
      "\n",
      "-------Running Epoch:8-------\n",
      "Trained 1 batches with current epoch cost: 0.3439364433288574\n",
      "At batch: 1, the training accuracy is: 92.2%\n",
      "At batch: 1, the test accuracy is: 82.8%\n",
      "Current run time is: 16287.724057912827 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 35.05549484491348\n",
      "At batch: 86, the training accuracy is: 89.1%\n",
      "At batch: 86, the test accuracy is: 86.7%\n",
      "Current run time is: 16633.73467540741 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 94.3500866740942\n",
      "At batch: 171, the training accuracy is: 74.2%\n",
      "At batch: 171, the test accuracy is: 68.8%\n",
      "Current run time is: 16967.9361743927 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 140.14786599576473\n",
      "At batch: 256, the training accuracy is: 86.7%\n",
      "At batch: 256, the test accuracy is: 86.7%\n",
      "Current run time is: 17310.074090242386 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 178.62013958394527\n",
      "At batch: 341, the training accuracy is: 84.4%\n",
      "At batch: 341, the test accuracy is: 82.8%\n",
      "Current run time is: 17650.62594485283 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 239.64992047846317\n",
      "At batch: 426, the training accuracy is: 82.0%\n",
      "At batch: 426, the test accuracy is: 86.7%\n",
      "Current run time is: 17989.627718925476 \n",
      "\n",
      "Epoch 8 completed out of: 10 loss: 241.057108596 , time: 1722.3369448184967 \n",
      "\n",
      "At end of epoch: 8, the training accuracy on batch is: 82.0%\n",
      "At end of epoch: 8, the test accuracy is: 85.9%\n",
      "[0.8359375, 0.8828125, 0.859375, 0.8125, 0.8203125, 0.84375, 0.8515625, 0.8046875, 0.859375]\n",
      "Total time taken for current epoch : 1724.764850 \n",
      "\n",
      "-------Running Epoch:9-------\n",
      "Trained 1 batches with current epoch cost: 0.4548954367637634\n",
      "At batch: 1, the training accuracy is: 78.9%\n",
      "At batch: 1, the test accuracy is: 87.5%\n",
      "Current run time is: 18011.949801683426 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 42.35470885038376\n",
      "At batch: 86, the training accuracy is: 79.7%\n",
      "At batch: 86, the test accuracy is: 81.2%\n",
      "Current run time is: 18351.434621572495 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 80.72951178252697\n",
      "At batch: 171, the training accuracy is: 85.9%\n",
      "At batch: 171, the test accuracy is: 85.9%\n",
      "Current run time is: 18705.884372234344 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 121.70966772735119\n",
      "At batch: 256, the training accuracy is: 89.8%\n",
      "At batch: 256, the test accuracy is: 90.6%\n",
      "Current run time is: 19047.59653878212 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 159.16382978856564\n",
      "At batch: 341, the training accuracy is: 89.1%\n",
      "At batch: 341, the test accuracy is: 83.6%\n",
      "Current run time is: 19394.59646987915 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 199.07004790008068\n",
      "At batch: 426, the training accuracy is: 88.3%\n",
      "At batch: 426, the test accuracy is: 87.5%\n",
      "Current run time is: 19731.977653503418 \n",
      "\n",
      "Epoch 9 completed out of: 10 loss: 200.37940605 , time: 1740.1004014015198 \n",
      "\n",
      "At end of epoch: 9, the training accuracy on batch is: 88.3%\n",
      "At end of epoch: 9, the test accuracy is: 85.2%\n",
      "[0.8359375, 0.8828125, 0.859375, 0.8125, 0.8203125, 0.84375, 0.8515625, 0.8046875, 0.859375, 0.8515625]\n",
      "Total time taken for current epoch : 1742.569618 \n",
      "\n",
      "-------Running Epoch:10-------\n",
      "Trained 1 batches with current epoch cost: 0.20331883430480957\n",
      "At batch: 1, the training accuracy is: 92.2%\n",
      "At batch: 1, the test accuracy is: 86.7%\n",
      "Current run time is: 19754.526399850845 \n",
      "\n",
      "Trained 86 batches with current epoch cost: 39.001240611076355\n",
      "At batch: 86, the training accuracy is: 93.8%\n",
      "At batch: 86, the test accuracy is: 92.2%\n",
      "Current run time is: 20104.19504261017 \n",
      "\n",
      "Trained 171 batches with current epoch cost: 87.61020919680595\n",
      "At batch: 171, the training accuracy is: 87.5%\n",
      "At batch: 171, the test accuracy is: 84.4%\n",
      "Current run time is: 20453.496018886566 \n",
      "\n",
      "Trained 256 batches with current epoch cost: 129.2725050151348\n",
      "At batch: 256, the training accuracy is: 85.9%\n",
      "At batch: 256, the test accuracy is: 83.6%\n",
      "Current run time is: 20808.24421095848 \n",
      "\n",
      "Trained 341 batches with current epoch cost: 163.790650755167\n",
      "At batch: 341, the training accuracy is: 88.3%\n",
      "At batch: 341, the test accuracy is: 92.2%\n",
      "Current run time is: 21162.628452777863 \n",
      "\n",
      "Trained 426 batches with current epoch cost: 200.57115118205547\n",
      "At batch: 426, the training accuracy is: 91.4%\n",
      "At batch: 426, the test accuracy is: 89.8%\n",
      "Current run time is: 21509.666525363922 \n",
      "\n",
      "Epoch 10 completed out of: 10 loss: 201.614731237 , time: 1775.1183123588562 \n",
      "\n",
      "At end of epoch: 10, the training accuracy on batch is: 91.4%\n",
      "At end of epoch: 10, the test accuracy is: 85.2%\n",
      "[0.8359375, 0.8828125, 0.859375, 0.8125, 0.8203125, 0.84375, 0.8515625, 0.8046875, 0.859375, 0.8515625, 0.8515625]\n",
      "Total time taken for current epoch : 1777.658019 \n",
      "\n",
      "At final epoch: 10, the test accuracy is: 89.4%, with cost 0.3776933252811432\n",
      "Total time taken for run : 21664.130794\n"
     ]
    }
   ],
   "source": [
    "learning_rate = learning_rate/2\n",
    "#optimize2(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoring model\n",
    "Here the model is restored and the values in the report match the recovered ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_acc(rnn_size,epochs):\n",
    "    \n",
    "    acc_test_list = []\n",
    "    acc_train_list = []\n",
    "    cost_train_list = []\n",
    "    cost_test_list =[]\n",
    "    b_size = 1000\n",
    "    num_train = len(mnist.train.labels)\n",
    "    num_test = len(mnist.test.labels)\n",
    "    \n",
    "    # Comment out here to use whole training set!\n",
    "    num_train = len(mnist.train.labels[:10000,:])\n",
    "    n_batches = num_train/b_size\n",
    "    count = 0\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    while i < num_train:\n",
    "        print('Processing batch number {} of {}.'.format(count+1,n_batches))\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + b_size, num_train)\n",
    "        \n",
    "        if j<= num_test:\n",
    "            \n",
    "            # Get the images from the test-set between index i and j.\n",
    "            images_test = mnist.test.images.reshape((-1, 784, 1))[i:j, :]\n",
    "\n",
    "            # Get the associated labels.\n",
    "            labels_test = mnist.test.labels[i:j, :]\n",
    "\n",
    "            acc_test, cost_test = sess.run([accuracy,cost],feed_dict = {x: binarize(images_test), y: labels_test})\n",
    "            #print(cost_test)\n",
    "\n",
    "            acc_test_list.append(acc_test)\n",
    "            cost_test_list.append(cost_test)\n",
    "        images_train = mnist.train.images.reshape((-1, 784, 1))[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels_test = mnist.train.labels[i:j, :]\n",
    "\n",
    "        acc_train,cost_train = sess.run([accuracy,cost],feed_dict = {x: binarize(images_train), y: labels_test})\n",
    "        acc_train_list.append(acc_train)\n",
    "        cost_train_list.append(cost_train)\n",
    "        i = j\n",
    "        count +=1\n",
    "        \n",
    "    #print(cost)\n",
    "    #print(time.time()-start)\n",
    "    print('\\n')\n",
    "    \n",
    "    total_acc_train = sum(acc_train_list)/len(acc_train_list)\n",
    "    total_acc_test = sum(acc_test_list)/len(acc_test_list)\n",
    "    total_cost_train = sum(cost_train_list)/len(cost_train_list)\n",
    "    total_cost_test = sum(cost_test_list)/len(cost_test_list)\n",
    "    #print(total_acc)\n",
    "    #total_cost = sum(cost)/len(cost)\n",
    "    print(time.time()-start)\n",
    "    print('The training accuracy for {} unit lstm model is {:.1%} after {} epochs'.format(rnn_size,total_acc_train,epochs))\n",
    "    print('The training cost for {} unit lstm model is {} after {} epochs \\n'.format(rnn_size,total_cost_train,epochs))\n",
    "    print('The test accuracy for {} unit lstm model is {:.1%} after {} epochs'.format(rnn_size,total_acc_test,epochs))\n",
    "    print('The test cost for {} unit lstm model is {} after {} epochs \\n'.format(rnn_size,total_cost_test,epochs))\n",
    "    return(total_acc_train,total_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_MDir = 'models/lstm128'\n",
    "save_model = os.path.join(save_MDir,'best_accuracyE10_LR0_0005')    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    "saver2restore = tf.train.Saver()\n",
    "saver2restore.restore(sess = sess, save_path= save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch number 1 of 55.0.\n",
      "Processing batch number 2 of 55.0.\n",
      "Processing batch number 3 of 55.0.\n",
      "Processing batch number 4 of 55.0.\n",
      "Processing batch number 5 of 55.0.\n",
      "Processing batch number 6 of 55.0.\n",
      "Processing batch number 7 of 55.0.\n",
      "Processing batch number 8 of 55.0.\n",
      "Processing batch number 9 of 55.0.\n",
      "Processing batch number 10 of 55.0.\n",
      "Processing batch number 11 of 55.0.\n",
      "Processing batch number 12 of 55.0.\n",
      "Processing batch number 13 of 55.0.\n",
      "Processing batch number 14 of 55.0.\n",
      "Processing batch number 15 of 55.0.\n",
      "Processing batch number 16 of 55.0.\n",
      "Processing batch number 17 of 55.0.\n",
      "Processing batch number 18 of 55.0.\n",
      "Processing batch number 19 of 55.0.\n",
      "Processing batch number 20 of 55.0.\n",
      "Processing batch number 21 of 55.0.\n",
      "Processing batch number 22 of 55.0.\n",
      "Processing batch number 23 of 55.0.\n",
      "Processing batch number 24 of 55.0.\n",
      "Processing batch number 25 of 55.0.\n",
      "Processing batch number 26 of 55.0.\n",
      "Processing batch number 27 of 55.0.\n",
      "Processing batch number 28 of 55.0.\n",
      "Processing batch number 29 of 55.0.\n",
      "Processing batch number 30 of 55.0.\n",
      "Processing batch number 31 of 55.0.\n",
      "Processing batch number 32 of 55.0.\n",
      "Processing batch number 33 of 55.0.\n",
      "Processing batch number 34 of 55.0.\n",
      "Processing batch number 35 of 55.0.\n",
      "Processing batch number 36 of 55.0.\n",
      "Processing batch number 37 of 55.0.\n",
      "Processing batch number 38 of 55.0.\n",
      "Processing batch number 39 of 55.0.\n",
      "Processing batch number 40 of 55.0.\n",
      "Processing batch number 41 of 55.0.\n",
      "Processing batch number 42 of 55.0.\n",
      "Processing batch number 43 of 55.0.\n",
      "Processing batch number 44 of 55.0.\n",
      "Processing batch number 45 of 55.0.\n",
      "Processing batch number 46 of 55.0.\n",
      "Processing batch number 47 of 55.0.\n",
      "Processing batch number 48 of 55.0.\n",
      "Processing batch number 49 of 55.0.\n",
      "Processing batch number 50 of 55.0.\n",
      "Processing batch number 51 of 55.0.\n",
      "Processing batch number 52 of 55.0.\n",
      "Processing batch number 53 of 55.0.\n",
      "Processing batch number 54 of 55.0.\n",
      "Processing batch number 55 of 55.0.\n",
      "\n",
      "\n",
      "503.246609210968\n",
      "The training accuracy for 128 unit GRU model is 89.0% after 30 epochs\n",
      "The training cost for 128 unit GRU model is 0.37947367375547236 after 30 epochs \n",
      "\n",
      "The test accuracy for 128 unit GRU model is 89.4% after 30 epochs\n",
      "The test cost for 128 unit GRU model is 0.37769326120615004 after 30 epochs \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the print_acc function to get the correct results\n",
    "print_acc(rnn_size=128, epochs = 30)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
