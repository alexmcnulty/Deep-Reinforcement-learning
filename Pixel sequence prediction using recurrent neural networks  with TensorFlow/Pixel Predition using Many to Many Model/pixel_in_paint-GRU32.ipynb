{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2b)\n",
    "Caculate the cost and visualize the in paintings for 32 64 and 128 models.\n",
    "Note that the models have to be changed manually but if it is run it will run the 32 model on the 10 length sequecne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pdb\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from itertools import chain\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Need to load the MNist data to work with\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)\n",
    "# one hot true gives the y labels as vectors with 1's which correspond to the number it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data that we will be working with:\n",
      "train set: 55000 \n",
      "valid set: 5000 \n",
      "test set: 10000 \n"
     ]
    }
   ],
   "source": [
    "print('The size of the data that we will be working with:')\n",
    "print('train set: {} '.format(len(mnist.train.labels)))\n",
    "print('valid set: {} '.format(len(mnist.validation.labels)))\n",
    "print('test set: {} '.format(len(mnist.test.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main RNN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN_predict(seq_len,input_pixels,rnn_size,weights,biases):\n",
    "\n",
    "\n",
    "    probs = []\n",
    "\n",
    "    # GRU layer\n",
    "    gru_cell = tf.nn.rnn_cell.GRUCell(num_units=rnn_size)\n",
    "    \n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=gru_cell, dtype=tf.float32, inputs=input_pixels)\n",
    "    # Shape outputs so its batch size=100*484, rnn_size=32\n",
    "    outputs = tf.reshape(outputs, [-1, rnn_size])\n",
    "    \n",
    "    # affine transformation\n",
    "    outputs = tf.matmul(outputs, weights) + biases\n",
    "    \n",
    "    # Reshape so that (batch size,pix_len)\n",
    "    outputs = tf.reshape(tf.nn.sigmoid(outputs), [-1, 484])\n",
    "\n",
    "    # 100 images, take the last output for all images.\n",
    "    output = tf.reshape(outputs[:, -1], [100, 1, 1])\n",
    "    # reshape the probabilites to be row vec and append as the first pediction\n",
    "    probs.append(tf.reshape(output, [100, 1]))\n",
    "   \n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    \n",
    "    # Here the next 10, 28, 300 pixels are predicted.\n",
    "    # Try frist using threshold of 0.5, ie rounding, for the outputs of the probabilites\n",
    "    # Then we need to the output of each pixel as input for the next cell\n",
    "    # sample later with the binomial.\n",
    "    # Since the input is 1 time step only one output.\n",
    "    for i in range(seq_len-1):\n",
    "        \n",
    "        # update the state each time\n",
    "        output, state = tf.nn.dynamic_rnn(cell=gru_cell, dtype=tf.float32, inputs=tf.round(output), initial_state=state)\n",
    "        output = tf.reshape(output, [-1, rnn_size])\n",
    "        output = tf.matmul(output, weights) + biases\n",
    "        output = tf.nn.sigmoid(output)\n",
    "        # need to reshape the probability to be easily stored\n",
    "        probs.append(tf.reshape(output, [100, 1]))\n",
    "        # reshape the output for the next input\n",
    "        output = tf.reshape(output, [100, 1, 1])\n",
    "        \n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize function for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binarize(images, threshold=0.1):\n",
    "    return (threshold < images).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "batch_size = 100\n",
    "chunk_size = 1\n",
    "n_chunks = 784\n",
    "rnn_size = 32\n",
    "first_pix = 484\n",
    "seq_len = 10\n",
    "full = first_pix+seq_len\n",
    "sampled_seq_list =[]\n",
    "cost_list=[]\n",
    "cost_values = []\n",
    "n_samples = 10\n",
    "random.seed(10)\n",
    "model = 128\n",
    "\n",
    "# Define the placeholders that will be used\n",
    "x = tf.placeholder('float', [None, 484,chunk_size])\n",
    "y = tf.placeholder('float',name='LabelData')\n",
    "\n",
    "# Taking the first 484 pixels of the fitst 100 images\n",
    "x_in_paint = x[:,0:first_pix,:]\n",
    "\n",
    "logs_path = '/tmp/tensorflow_logs/example'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define weights to be reloaded later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_normal([rnn_size, 1]))\n",
    "biases =  tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ready for session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = RNN_predict(seq_len,x,rnn_size,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(init)\n",
    "    \n",
    "    #save_MDir = 'models/Task2/gru128/'\n",
    "    save_MDir = 'models/Task2/gru32/'\n",
    "    #save_MDir = 'models/Task2/gru64/'\n",
    "    \n",
    "    save_model = os.path.join(save_MDir,'best_accuracy_Take_3')\n",
    "    saver2restore = tf.train.Saver()\n",
    "    saver2restore.restore(sess = sess, save_path= save_model)\n",
    "\n",
    "    \n",
    "    batch_x = mnist.test.images[:batch_size,:484]\n",
    "    batch_x = binarize(batch_x)\n",
    "    batch_x = batch_x.reshape(batch_size,484,chunk_size)\n",
    "    batch_y = mnist.test.labels[:batch_size]\n",
    "    \n",
    "    # main work done here\n",
    "    pix_probs = sess.run(probs,feed_dict={x:batch_x})\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pix_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost\n",
    "Need to get the images ready and calculate the Xent between the sample pixels and the likelihood aswell as of the ground truth of truth and the pixel sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pix_probs = np.stack(pix_probs,axis = 1).reshape(batch_size,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 300)\n"
     ]
    }
   ],
   "source": [
    "# Need to get the last 300 pixels from the test images to calculate the Xent\n",
    "im_test = binarize(mnist.test.images[:batch_size,-300:])\n",
    "print(im_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_seq_list =[]\n",
    "cost_list=[]\n",
    "cost_values = []\n",
    "for k in range(n_samples):\n",
    "    if seq_len>1:\n",
    "        # need to sample from the probabilies. Here a binomial distrbution is used to see if a the pixel is 1 or 0\n",
    "        sampled_seq = np.random.binomial(n = 1, p = pix_probs)\n",
    "        \n",
    "        sampled_costs = -np.sum(sampled_seq*np.log(pix_probs)+(1-sampled_seq)*np.log(1-pix_probs),axis = 1)\n",
    "        cost_list.append(sampled_costs)\n",
    "        \n",
    "        # Get the n_sample costs\n",
    "        cost_values.append(np.sum(sampled_costs))\n",
    "        \n",
    "        sampled_seq_list.append(sampled_seq)\n",
    "        \n",
    "        \n",
    "        # add the binarized sequence to list to \n",
    "    # For the 1 pixel prediction case just round.\n",
    "    else:\n",
    "        \n",
    "        # do the same for the one pixel case\n",
    "        binarize_pixel = np.random.binomial(n = 1, p = pix_probs)\n",
    "        sampled_costs = -np.sum(binarize_pixel*np.log(pix_probs)+(1-binarize_pixel)*(np.log(1-pix_probs)))\n",
    "        cost_values.append(sampled_costs)\n",
    "        sampled_seq_list.append(binarize_pixel)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost for the sampled sequences of length 10 is: 1.96989\n",
      "The cost for the sampled sequences of length 10 with the Ground Truth is: 4.57836\n"
     ]
    }
   ],
   "source": [
    "# Get the loss: \n",
    "#between the sampled seq and the pred prob:\n",
    "Final_sample_cost = sum(cost_values)/(len(cost_values)*batch_size)\n",
    "print('The cost for the sampled sequences of length {} is: {:.6}'.format(seq_len,Final_sample_cost))\n",
    "\n",
    "# Ground truth and pred_probb:\n",
    "GT_costs = -np.sum(im_test[:,:seq_len]*np.log(pix_probs)+(1-im_test[:,:seq_len])*np.log(1-pix_probs),axis = 1)\n",
    "GT_costs = np.sum(GT_costs)\n",
    "Final_GT_cost = GT_costs/batch_size\n",
    "print('The cost for the sampled sequences of length {} with the Ground Truth is: {:.6}'.format(seq_len,Final_GT_cost))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print images\n",
    "Need to find the images which represent good, bad and high variance predictions. Using the cost as a measure of how well a prediction does, the indices are found to be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53, 54, 58]\n"
     ]
    }
   ],
   "source": [
    "# since a the cost is a list of vectors, need to stack then\n",
    "# on top of each other in order to work with them easier\n",
    "if seq_len > 1:\n",
    "    costs = np.stack(cost_list, axis = 1)\n",
    "\n",
    "    # Take in the n samples for the 100 images, and take the average\n",
    "    # of the samples for each pixel. Take the higher mean to \n",
    "    # be the best prediction, the min to be the worst.\n",
    "    mean_costs = np.mean(costs,axis =1)\n",
    "\n",
    "    # Good has lowest mean cost, bad has high and high variacne is the max variance of the cost across the samples.\n",
    "    good = np.argmin(mean_costs)\n",
    "    bad = np.argmax(mean_costs)\n",
    "    var_ind = np.var(costs,axis =1)\n",
    "    ugly = np.argmax(var_ind)\n",
    "    # find the good the bad the high variance costs.\n",
    "    im_indexes = [good,bad,ugly]\n",
    "    print(im_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the good the bad the high variance costs.\n",
    "#im_indexes = [good,bad,ugly]\n",
    "#print(im_indexes)\n",
    "# Define the test images and split them into the intial 484 and the prediction image parts.\n",
    "test_images = binarize(mnist.test.images[0:100,:])\n",
    "test_484 = test_images[:,0:first_pix]\n",
    "test_end = test_images[:,first_pix:]\n",
    "#10 = [69, 27, 15]\n",
    "#28 = [37, 27, 52]\n",
    "#300 = [2, 68, 30]\n",
    "if seq_len ==10:\n",
    "    im_indexes = [69, 27, 15]\n",
    "if seq_len ==28:\n",
    "    im_indexes = [37, 27, 52]\n",
    "if seq_len ==300:\n",
    "    im_indexes = [2, 68, 30]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_pred(seq_len, n_samples,im_indexes,test_images, model ,n_chunks=784):\n",
    "    pred_images_good =[]\n",
    "    pred_images_bad =[]\n",
    "    pred_images_ugly =[]\n",
    "    seq_ind = first_pix+seq_len \n",
    "    good = im_indexes[0]\n",
    "    bad = im_indexes[1]\n",
    "    ugly = im_indexes[2]\n",
    "    test_484 = test_images[:,0:first_pix]\n",
    "    test_end = test_images[:,first_pix:]\n",
    "    test_end_mask = test_end\n",
    "    test_end_mask[:,seq_len:] = 0.6\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        \n",
    "        sampled_seqs = sampled_seq_list[i]\n",
    "        sampled_seqs_good = sampled_seqs[good,:]\n",
    "        sampled_seqs_bad = sampled_seqs[bad,:]\n",
    "        sampled_seqs_ugly = sampled_seqs[ugly,:]\n",
    "        \n",
    "        sampled_seqs_good = np.append(test_484[good,:],sampled_seqs_good,axis = 0)\n",
    "        sampled_seqs_bad = np.append(test_484[bad,:],sampled_seqs_bad,axis = 0)\n",
    "        sampled_seqs_ugly = np.append(test_484[ugly,:],sampled_seqs_ugly,axis = 0)\n",
    "\n",
    "        pred_seqs_good = np.append(sampled_seqs_good,test_end_mask[good,seq_len:].reshape(1,(n_chunks-seq_ind))).reshape(28,28)\n",
    "        pred_seqs_bad = np.append(sampled_seqs_bad,test_end_mask[bad,seq_len:].reshape(1,(n_chunks-seq_ind))).reshape(28,28)\n",
    "        pred_seqs_ugly = np.append(sampled_seqs_ugly,test_end_mask[ugly,seq_len:].reshape(1,(n_chunks-seq_ind))).reshape(28,28)\n",
    "\n",
    "        pred_images_good.append(pred_seqs_good)\n",
    "        pred_images_bad.append(pred_seqs_bad)\n",
    "        pred_images_ugly.append(pred_seqs_ugly)\n",
    "        \n",
    "        #pred_images_good.append(sampled_seqs_good)\n",
    "        #pred_images_bad.append(sampled_seqs_bad)\n",
    "        #pred_images_ugly.append(sampled_seqs_ugly)        \n",
    "\n",
    "    pred_images = list(chain(pred_images_good,pred_images_bad,pred_images_ugly))    \n",
    "    #print(len(pred_images))\n",
    "\n",
    "\n",
    "    GT_images = []\n",
    "    for i in range(len(im_indexes)):\n",
    "        ind = im_indexes[i]\n",
    "        im = test_images[ind,:].reshape(28,28)\n",
    "        GT_images.append(im)\n",
    "\n",
    "\n",
    "\n",
    "    f, axarr = plt.subplots(3,6)\n",
    "    count = 0\n",
    "    string = ['Good', 'Bad', 'Var']\n",
    "    for i in range(3):\n",
    "        for j in range(6):\n",
    "            if j == 5:\n",
    "                axarr[i,j].imshow(GT_images[i],  cmap=\"jet\")\n",
    "                axarr[i,j].set_title(\"{} GT\".format(string[i]))\n",
    "                axarr[i,j].axis('off')\n",
    "            else:   \n",
    "                axarr[i,j].imshow(pred_images[count],  cmap=\"jet\")\n",
    "                axarr[i,j].set_title(\"{}\".format(string[i]))\n",
    "                axarr[i,j].axis('off')\n",
    "                count+=1\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('C:/Users/Alex/.ipython/CW2/models/Task2/images/GRU%d_pred_images_%d.png' % (model,seq_len), dpi =150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEMCAYAAAB3Ful8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwEU2bAWpQBytAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c7dded2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the print function for the longer sequences to get muliple images\n",
    "if seq_len>1:\n",
    "    print_pred(seq_len, 5 ,im_indexes,test_images,rnn_size,n_chunks=784)\n",
    "\n",
    "    \n",
    "elif seq_len ==1:\n",
    "    im1 = 1\n",
    "    seq_ind = first_pix+seq_len \n",
    "    test_484 = test_images[:,0:first_pix]\n",
    "    test_end = test_images[:,first_pix:]\n",
    "    test_end_mask = test_end\n",
    "    test_end_mask[:,seq_len:] = 0.6   \n",
    "    sampled_seqs = sampled_seq_list[im1]\n",
    "    sampled_seqs_good = sampled_seqs[im1,:]\n",
    "    sampled_seqs_good = np.append(test_484[im1,:],sampled_seqs_good,axis = 0)\n",
    "    pred_seqs_good = np.append(sampled_seqs_good,test_end_mask[im1,seq_len:].reshape(1,(n_chunks-seq_ind))).reshape(28,28)\n",
    "    plt.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "    plt.title('One Pixel')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    plt.imshow(pred_seqs_good, cmap='jet')\n",
    "    #plt.savefig('C:/Users/Alex/.ipython/CW2/models/Task2/images/GRU%d_pred_images_%d.png' % (rnn_size,seq_len), dpi =150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUunfMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c7ddd7b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(binarize(mnist.test.images[0:100,:])[1,:].reshape(28,28), cmap='jet')\n",
    "#plt.savefig('C:/Users/Alex/.ipython/CW2/models/Task2/images/one_pix_gt.png' , dpi =150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
