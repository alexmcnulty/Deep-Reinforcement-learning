{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2b)\n",
    "Caculate the cost and visualize the in paintings for 3 layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pdb\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from itertools import chain\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Need to load the MNist data to work with\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)\n",
    "# one hot true gives the y labels as vectors with 1's which correspond to the number it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data that we will be working with:\n",
      "train set: 55000 \n",
      "valid set: 5000 \n",
      "test set: 10000 \n"
     ]
    }
   ],
   "source": [
    "print('The size of the data that we will be working with:')\n",
    "print('train set: {} '.format(len(mnist.train.labels)))\n",
    "print('valid set: {} '.format(len(mnist.validation.labels)))\n",
    "print('test set: {} '.format(len(mnist.test.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main RNN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN_predict(seq_len,input_pixels,rnn_size,weights,biases):\n",
    "\n",
    "\n",
    "    probs = []\n",
    "\n",
    "    # GRU layer\n",
    "    gru_cell = tf.nn.rnn_cell.GRUCell(num_units=rnn_size)\n",
    "    gru_cell = tf.nn.rnn_cell.MultiRNNCell(cells=[gru_cell] * 3, state_is_tuple=True)\n",
    "\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=gru_cell, dtype=tf.float32, inputs=input_pixels)\n",
    "    \n",
    "    \n",
    "    # Shape outputs so its batch size=100*484, rnn_size=32\n",
    "    outputs = tf.reshape(outputs, [-1, rnn_size])\n",
    "    \n",
    "    # affine transformation\n",
    "    outputs = tf.matmul(outputs, weights) + biases\n",
    "    \n",
    "    # Reshape so that (batch size,pix_len)\n",
    "    outputs = tf.reshape(tf.nn.sigmoid(outputs), [-1, 484])\n",
    "\n",
    "    # 100 images, take the last output for all images.\n",
    "    output = tf.reshape(outputs[:, -1], [100, 1, 1])\n",
    "    # reshape the probabilites to be row vec and append as the first pediction\n",
    "    probs.append(tf.reshape(output, [100, 1]))\n",
    "   \n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    \n",
    "    # Here the next 10, 28, 300 pixels are predicted.\n",
    "    # Try frist using threshold of 0.5, ie rounding, for the outputs of the probabilites\n",
    "    # Then we need to the output of each pixel as input for the next cell\n",
    "    # sample later with the binomial.\n",
    "    # Since the input is 1 time step only one output.\n",
    "    for i in range(seq_len-1):\n",
    "        \n",
    "        # update the state each time\n",
    "        output, state = tf.nn.dynamic_rnn(cell=gru_cell, dtype=tf.float32, inputs=tf.round(output), initial_state=state)\n",
    "        output = tf.reshape(output, [-1, rnn_size])\n",
    "        output = tf.matmul(output, weights) + biases\n",
    "        output = tf.nn.sigmoid(output)\n",
    "        # need to reshape the probability to be easily stored\n",
    "        probs.append(tf.reshape(output, [100, 1]))\n",
    "        # reshape the output for the next input\n",
    "        output = tf.reshape(output, [100, 1, 1])\n",
    "        \n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize function for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binarize(images, threshold=0.1):\n",
    "    return (threshold < images).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "batch_size = 100\n",
    "chunk_size = 1\n",
    "n_chunks = 784\n",
    "rnn_size = 32\n",
    "first_pix = 484\n",
    "seq_len = 300\n",
    "full = first_pix+seq_len\n",
    "sampled_seq_list =[]\n",
    "cost_list=[]\n",
    "cost_values = []\n",
    "n_samples = 10\n",
    "random.seed(10)\n",
    "model = 128\n",
    "\n",
    "# Define the placeholders that will be used\n",
    "x = tf.placeholder('float', [None, 484,chunk_size])\n",
    "y = tf.placeholder('float',name='LabelData')\n",
    "\n",
    "# Taking the first 484 pixels of the fitst 100 images\n",
    "x_in_paint = x[:,0:first_pix,:]\n",
    "\n",
    "logs_path = '/tmp/tensorflow_logs/example'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define weights to be reloaded later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_normal([rnn_size, 1]))\n",
    "biases =  tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ready for session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = RNN_predict(seq_len,x,rnn_size,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(init)\n",
    "    \n",
    "    #save_MDir = 'models/Task2/gru128/'\n",
    "    #save_MDir = 'models/Task2/gru32/'\n",
    "    #save_MDir = 'models/Task2/gru64/'\n",
    "    save_MDir = 'models/Task2/gru3_layer/'\n",
    "    save_model = os.path.join(save_MDir,'best_accuracy3')\n",
    "    saver2restore = tf.train.Saver()\n",
    "    saver2restore.restore(sess = sess, save_path= save_model)\n",
    "\n",
    "    \n",
    "    batch_x = mnist.test.images[:batch_size,:484]\n",
    "    batch_x = binarize(batch_x)\n",
    "    batch_x = batch_x.reshape(batch_size,484,chunk_size)\n",
    "    batch_y = mnist.test.labels[:batch_size]\n",
    "    \n",
    "    # main work done here\n",
    "    pix_probs = sess.run(probs,feed_dict={x:batch_x})\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pix_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost\n",
    "Need to get the images ready and calculate the Xent between the sample pixels and the likelihood aswell as of the ground truth of truth and the pixel sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pix_probs = np.stack(pix_probs,axis = 1).reshape(batch_size,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 300)\n"
     ]
    }
   ],
   "source": [
    "# Need to get the last 300 pixels from the test images to calculate the Xent\n",
    "im_test = binarize(mnist.test.images[:batch_size,-300:])\n",
    "print(im_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_seq_list =[]\n",
    "cost_list=[]\n",
    "cost_values = []\n",
    "for k in range(n_samples):\n",
    "    if seq_len>1:\n",
    "        # need to sample from the probabilies. Here a binomial distrbution is used to see if a the pixel is 1 or 0\n",
    "        sampled_seq = np.random.binomial(n = 1, p = pix_probs)\n",
    "        \n",
    "        sampled_costs = -np.sum(sampled_seq*np.log(pix_probs)+(1-sampled_seq)*np.log(1-pix_probs),axis = 1)\n",
    "        cost_list.append(sampled_costs)\n",
    "        \n",
    "        # Get the n_sample costs\n",
    "        cost_values.append(np.sum(sampled_costs))\n",
    "        \n",
    "        sampled_seq_list.append(sampled_seq)\n",
    "        \n",
    "        \n",
    "        # add the binarized sequence to list to \n",
    "    # For the 1 pixel prediction case just round.\n",
    "    else:\n",
    "        \n",
    "            \n",
    "        binarize_pixel = np.random.binomial(n = 1, p = pix_probs)\n",
    "        sampled_costs = -np.sum(binarize_pixel*np.log(pix_probs)+(1-binarize_pixel)*(np.log(1-pix_probs)))\n",
    "        cost_values.append(sampled_costs)\n",
    "        sampled_seq_list.append(binarize_pixel)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost for the sampled sequences of length 300 is: 18.4037\n",
      "The cost for the sampled sequences of length 300 with the Ground Truth is: 153.472\n"
     ]
    }
   ],
   "source": [
    "# Get the loss: \n",
    "#between the sampled seq and the pred prob:\n",
    "Final_sample_cost = sum(cost_values)/(len(cost_values)*batch_size)\n",
    "print('The cost for the sampled sequences of length {} is: {:.6}'.format(seq_len,Final_sample_cost))\n",
    "\n",
    "# Ground truth and pred_probb:\n",
    "GT_costs = -np.sum(im_test[:,:seq_len]*np.log(pix_probs)+(1-im_test[:,:seq_len])*np.log(1-pix_probs),axis = 1)\n",
    "GT_costs = np.sum(GT_costs)\n",
    "Final_GT_cost = GT_costs/batch_size\n",
    "print('The cost for the sampled sequences of length {} with the Ground Truth is: {:.6}'.format(seq_len,Final_GT_cost))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print images\n",
    "Need to find the images which represent good, bad and high variance predictions. Using the cost as a measure of how well a prediction does, the indices are found to be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 43, 13]\n"
     ]
    }
   ],
   "source": [
    "# since a the cost is a list of vectors, need to stack then\n",
    "# on top of each other in order to work with them easier\n",
    "if seq_len > 1:\n",
    "    costs = np.stack(cost_list, axis = 1)\n",
    "\n",
    "    # Take in the n samples for the 100 images, and take the average\n",
    "    # of the samples for each pixel. Take the higher mean to \n",
    "    # be the best prediction, the min to be the worst.\n",
    "    mean_costs = np.mean(costs,axis =1)\n",
    "\n",
    "    # Good has lowest mean cost, bad has high and high variacne is the max variance of the cost across the samples.\n",
    "    good = np.argmin(mean_costs)\n",
    "    bad = np.argmax(mean_costs)\n",
    "    var_ind = np.var(costs,axis =1)\n",
    "    ugly = np.argmax(var_ind)\n",
    "    # find the good the bad the high variance costs.\n",
    "    im_indexes = [good,bad,ugly]\n",
    "    print(im_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the good the bad the high variance costs.\n",
    "#im_indexes = [good,bad,ugly]\n",
    "#print(im_indexes)\n",
    "# Define the test images and split them into the intial 484 and the prediction image parts.\n",
    "test_images = binarize(mnist.test.images[0:100,:])\n",
    "test_484 = test_images[:,0:first_pix]\n",
    "test_end = test_images[:,first_pix:]\n",
    "#10 = [69, 27, 15]\n",
    "#28 = [37, 27, 52]\n",
    "#300 = [2, 68, 30]\n",
    "if seq_len ==10:\n",
    "    im_indexes = [69, 27, 15]\n",
    "if seq_len ==28:\n",
    "    im_indexes = [37, 27, 52]\n",
    "if seq_len ==300:\n",
    "    im_indexes = [2, 68, 30]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_pred(seq_len, n_samples,im_indexes,test_images, model ,n_chunks=784):\n",
    "    pred_images_good =[]\n",
    "    pred_images_bad =[]\n",
    "    pred_images_ugly =[]\n",
    "    seq_ind = first_pix+seq_len \n",
    "    good = im_indexes[0]\n",
    "    bad = im_indexes[1]\n",
    "    ugly = im_indexes[2]\n",
    "    test_484 = test_images[:,0:first_pix]\n",
    "    test_end = test_images[:,first_pix:]\n",
    "    test_end_mask = test_end\n",
    "    test_end_mask[:,seq_len:] = 0.6\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        \n",
    "        sampled_seqs = sampled_seq_list[i]\n",
    "        sampled_seqs_good = sampled_seqs[good,:]\n",
    "        sampled_seqs_bad = sampled_seqs[bad,:]\n",
    "        sampled_seqs_ugly = sampled_seqs[ugly,:]\n",
    "        \n",
    "        sampled_seqs_good = np.append(test_484[good,:],sampled_seqs_good,axis = 0)\n",
    "        sampled_seqs_bad = np.append(test_484[bad,:],sampled_seqs_bad,axis = 0)\n",
    "        sampled_seqs_ugly = np.append(test_484[ugly,:],sampled_seqs_ugly,axis = 0)\n",
    "\n",
    "        pred_seqs_good = np.append(sampled_seqs_good,test_end_mask[good,seq_len:].reshape(1,(n_chunks-seq_ind))).reshape(28,28)\n",
    "        pred_seqs_bad = np.append(sampled_seqs_bad,test_end_mask[bad,seq_len:].reshape(1,(n_chunks-seq_ind))).reshape(28,28)\n",
    "        pred_seqs_ugly = np.append(sampled_seqs_ugly,test_end_mask[ugly,seq_len:].reshape(1,(n_chunks-seq_ind))).reshape(28,28)\n",
    "\n",
    "        pred_images_good.append(pred_seqs_good)\n",
    "        pred_images_bad.append(pred_seqs_bad)\n",
    "        pred_images_ugly.append(pred_seqs_ugly)\n",
    "        \n",
    "        #pred_images_good.append(sampled_seqs_good)\n",
    "        #pred_images_bad.append(sampled_seqs_bad)\n",
    "        #pred_images_ugly.append(sampled_seqs_ugly)        \n",
    "\n",
    "    pred_images = list(chain(pred_images_good,pred_images_bad,pred_images_ugly))    \n",
    "    #print(len(pred_images))\n",
    "\n",
    "\n",
    "    GT_images = []\n",
    "    for i in range(len(im_indexes)):\n",
    "        ind = im_indexes[i]\n",
    "        im = test_images[ind,:].reshape(28,28)\n",
    "        GT_images.append(im)\n",
    "\n",
    "\n",
    "\n",
    "    f, axarr = plt.subplots(3,6)\n",
    "    count = 0\n",
    "    string = ['Good', 'Bad', 'Var']\n",
    "    for i in range(3):\n",
    "        for j in range(6):\n",
    "            if j == 5:\n",
    "                axarr[i,j].imshow(GT_images[i],  cmap=\"jet\")\n",
    "                axarr[i,j].set_title(\"{} GT\".format(string[i]))\n",
    "                axarr[i,j].axis('off')\n",
    "            else:   \n",
    "                axarr[i,j].imshow(pred_images[count],  cmap=\"jet\")\n",
    "                axarr[i,j].set_title(\"{}\".format(string[i]))\n",
    "                axarr[i,j].axis('off')\n",
    "                count+=1\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('C:/Users/Alex/.ipython/CW2/models/Task2/images/3layer_GRU%d_pred_images_%d.png' % (model,seq_len), dpi =150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEMCAYAAAB3Ful8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c6062762e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if seq_len>1:\n",
    "    print_pred(seq_len, 5 ,im_indexes,test_images,rnn_size,n_chunks=784)\n",
    "\n",
    "    \n",
    "elif seq_len ==1:\n",
    "    im1 = 1\n",
    "    seq_ind = first_pix+seq_len \n",
    "    test_484 = test_images[:,0:first_pix]\n",
    "    test_end = test_images[:,first_pix:]\n",
    "    test_end_mask = test_end\n",
    "    test_end_mask[:,seq_len:] = 0.6   \n",
    "    sampled_seqs = sampled_seq_list[im1]\n",
    "    sampled_seqs_good = sampled_seqs[im1,:]\n",
    "    sampled_seqs_good = np.append(test_484[im1,:],sampled_seqs_good,axis = 0)\n",
    "    pred_seqs_good = np.append(sampled_seqs_good,test_end_mask[im1,seq_len:].reshape(1,(n_chunks-seq_ind))).reshape(28,28)\n",
    "    plt.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "    plt.title('One Pixel')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    plt.imshow(pred_seqs_good, cmap='jet')\n",
    "    #plt.savefig('C:/Users/Alex/.ipython/CW2/models/3layer_GRU%d_pred_images_%d.png' % (rnn_size,seq_len), dpi =150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
