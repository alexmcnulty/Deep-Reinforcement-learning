{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: 2X2 pixel inpainting\n",
    "In this part we need to get the most likely image given both past and futre pixels. In order to do this, all possible outcomes(pixel predictions) are compared and the outcomes of the lowest cost are chossen. This time there is 16 possible outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pdb\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from itertools import chain\n",
    "import random\n",
    "import copy\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Need to load the MNist data to work with\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)\n",
    "# one hot true gives the y labels as vectors with 1's which correspond to the number it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load images\n",
    "twobytwopixels_inpainting = np.load('2X2_pixels_inpainting.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the missing pixels\n",
    "missing_pixels = twobytwopixels_inpainting[0,:,:]\n",
    "pic_GT = twobytwopixels_inpainting[1,:,:]\n",
    "miss_pix_ind = np.where(missing_pixels == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshpape into useable shape\n",
    "miss_pix_ind =miss_pix_ind[1].reshape(1000,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to copy the missing pixel image 16 times\n",
    "# should have used the np.repeat but didn't find it till after\n",
    "\n",
    "pixels_0000 = copy.deepcopy(missing_pixels)\n",
    "\n",
    "pixels_1000 = copy.deepcopy(missing_pixels)\n",
    "pixels_0100 = copy.deepcopy(missing_pixels)\n",
    "pixels_0010 = copy.deepcopy(missing_pixels)\n",
    "pixels_0001 = copy.deepcopy(missing_pixels)\n",
    "\n",
    "pixels_1100 = copy.deepcopy(missing_pixels)\n",
    "pixels_1010 = copy.deepcopy(missing_pixels)\n",
    "pixels_1001 = copy.deepcopy(missing_pixels)\n",
    "pixels_0110 = copy.deepcopy(missing_pixels)\n",
    "pixels_0101 = copy.deepcopy(missing_pixels)\n",
    "pixels_0011 = copy.deepcopy(missing_pixels)\n",
    "\n",
    "pixels_1110 = copy.deepcopy(missing_pixels)\n",
    "pixels_1101 = copy.deepcopy(missing_pixels)\n",
    "pixels_1011 = copy.deepcopy(missing_pixels)\n",
    "pixels_0111 = copy.deepcopy(missing_pixels)\n",
    "pixels_1111 = copy.deepcopy(missing_pixels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to create the images with the correct missing pixel sequence for the 16 possible combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do it for the easy cases\n",
    "for i in range(1000):\n",
    "    pixels_0000[i,miss_pix_ind[i,:]] = 0\n",
    "    pixels_1111[i,miss_pix_ind[i,:]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do it for the 14 other images\n",
    "for i in range(1000):\n",
    "    for j in range(miss_pix_ind.shape[1]):\n",
    "        if j == 0:\n",
    "            pixels_1000[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0100[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0010[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0001[i,miss_pix_ind[i,j]] = 0\n",
    "\n",
    "            pixels_1100[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1010[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1001[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0110[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0101[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0011[i,miss_pix_ind[i,j]] = 0\n",
    "\n",
    "            pixels_1110[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1101[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1011[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0111[i,miss_pix_ind[i,j]] = 0\n",
    "             \n",
    "            \n",
    "\n",
    "        elif j == 1:\n",
    "            pixels_1000[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0100[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0010[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0001[i,miss_pix_ind[i,j]] = 0\n",
    "\n",
    "            pixels_1100[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1010[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_1001[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0110[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0101[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0011[i,miss_pix_ind[i,j]] = 0\n",
    "\n",
    "            pixels_1110[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1101[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1011[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0111[i,miss_pix_ind[i,j]] = 1      \n",
    "            \n",
    "        elif j == 2:\n",
    "            pixels_1000[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0100[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0010[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0001[i,miss_pix_ind[i,j]] = 0\n",
    "\n",
    "            pixels_1100[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_1010[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1001[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0110[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0101[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0011[i,miss_pix_ind[i,j]] = 1\n",
    "\n",
    "            pixels_1110[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1101[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_1011[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0111[i,miss_pix_ind[i,j]] = 1         \n",
    "        \n",
    "        elif j == 3:\n",
    "            pixels_1000[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0100[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0010[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0001[i,miss_pix_ind[i,j]] = 1\n",
    "\n",
    "            pixels_1100[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_1010[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_1001[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0110[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_0101[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0011[i,miss_pix_ind[i,j]] = 1\n",
    "\n",
    "            pixels_1110[i,miss_pix_ind[i,j]] = 0\n",
    "            pixels_1101[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_1011[i,miss_pix_ind[i,j]] = 1\n",
    "            pixels_0111[i,miss_pix_ind[i,j]] = 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN_predict(input_pixels,gt_pixels,rnn_size):\n",
    "\n",
    "\n",
    "    probs = []\n",
    "\n",
    "    # GRU layer\n",
    "    gru_cell = tf.nn.rnn_cell.GRUCell(num_units=rnn_size)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=gru_cell, dtype=tf.float32, inputs=input_pixels)\n",
    "    # Shape outputs so its batch size=100*484, rnn_size=32\n",
    "    outputs = tf.reshape(outputs, [-1, rnn_size])\n",
    "    \n",
    "    # affine transformation\n",
    "    outputs = tf.matmul(outputs, weights) + biases\n",
    "    \n",
    "    # Reshape so that (batch size,pix_len)\n",
    "    sampled = tf.reshape(input_pixels,[-1, 784])\n",
    "    #gt = tf.reshape(gt_pixels,[-1, 784])\n",
    "    gt = gt_pixels\n",
    "    logits = tf.reshape((outputs), [-1, 784])\n",
    "    # Calculate the cost between the ground truth image and the probs(outcomes)    \n",
    "    cost_gt_out = -tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(targets=gt[:,1:], logits=logits[:,:-1]), axis = 1)\n",
    "    \n",
    "    # Calculate the cost between the image you sampled and the probs(outcomes)    \n",
    "    cost_sample = -tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(targets=sampled[:,1:], logits=logits[:,:-1]), axis = 1)\n",
    "    \n",
    "    #outputs = tf.reshape(tf.nn.sigmoid(outputs), [-1, 784])\n",
    "    return cost_sample,cost_gt_out\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the placeholders, variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "batch_size = 100\n",
    "chunk_size = 1\n",
    "n_chunks = 784\n",
    "rnn_size = 128\n",
    "first_pix = 484\n",
    "#seq_len = 10\n",
    "#\n",
    "#full = first_pix+seq_len\n",
    "sampled_seq_list =[]\n",
    "cost_list=[]\n",
    "cost_values = []\n",
    "n_samples = 10\n",
    "random.seed(10)\n",
    "seq_len = miss_pix_ind\n",
    "\n",
    "# Define the placeholders that will be used\n",
    "x = tf.placeholder('float', [None, n_chunks,chunk_size])\n",
    "y = tf.placeholder('float', [None, n_chunks])\n",
    "\n",
    "# Taking the first 484 pixels of the fitst 100 images\n",
    "x_in_paint = x[:,0:first_pix,:]\n",
    "\n",
    "logs_path = '/tmp/tensorflow_logs/example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_normal([rnn_size, 1]))\n",
    "biases =  tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(images, threshold=0.1):\n",
    "    return (threshold < images).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the graph to be run\n",
    "cost_sampled, cost_gt = RNN_predict(x,y,rnn_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store the images in a list\n",
    "pixel_list = []\n",
    "\n",
    "pixel_list.append(pixels_0000)\n",
    "pixel_list.append(pixels_1000)\n",
    "pixel_list.append(pixels_0100)\n",
    "pixel_list.append(pixels_0010)\n",
    "pixel_list.append(pixels_0001)\n",
    "pixel_list.append(pixels_1100)\n",
    "pixel_list.append(pixels_1010)\n",
    "pixel_list.append(pixels_1001)\n",
    "pixel_list.append(pixels_0110)\n",
    "pixel_list.append(pixels_0101)\n",
    "pixel_list.append(pixels_0011)\n",
    "pixel_list.append(pixels_1110)\n",
    "pixel_list.append(pixels_1101)\n",
    "pixel_list.append(pixels_1011)\n",
    "pixel_list.append(pixels_0111)\n",
    "pixel_list.append(pixels_1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to process 1 set of images: 5.104594469070435\n",
      "Time to process 2 set of images: 10.282800674438477\n",
      "Time to process 3 set of images: 15.241260528564453\n",
      "Time to process 4 set of images: 20.360339879989624\n",
      "Time to process 5 set of images: 25.114092588424683\n",
      "Time to process 6 set of images: 30.072290658950806\n",
      "Time to process 7 set of images: 34.910362243652344\n",
      "Time to process 8 set of images: 39.79884219169617\n",
      "Time to process 9 set of images: 45.01382899284363\n",
      "Time to process 10 set of images: 51.213409662246704\n",
      "Time to process 11 set of images: 56.38880705833435\n",
      "Time to process 12 set of images: 61.421570777893066\n",
      "Time to process 13 set of images: 66.47544884681702\n",
      "Time to process 14 set of images: 71.53541445732117\n",
      "Time to process 15 set of images: 76.37879085540771\n",
      "Time to process 16 set of images: 81.40509486198425\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "cost_samp_list = []\n",
    "cost_gt_list = []\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(init)\n",
    "    start = time.time()\n",
    "    save_MDir = 'models/Task2/gru128/'\n",
    "    save_model = os.path.join(save_MDir,'best_accuracy_3')\n",
    "    saver2restore = tf.train.Saver()\n",
    "    saver2restore.restore(sess = sess, save_path= save_model)\n",
    "    \n",
    "    # feed in each image and calculate the gt cost and the sampled cost for each set of images\n",
    "    for image in range(len(pixel_list)):\n",
    "        \n",
    "        batch_x = pixel_list[image]\n",
    "        batch_x = binarize(batch_x)\n",
    "        batch_x = batch_x.reshape(1000,784,chunk_size)\n",
    "\n",
    "        # main work done here\n",
    "        cost_samp,cost_gts = sess.run([cost_sampled,cost_gt],feed_dict={x:batch_x, y:pic_GT})\n",
    "        cost_samp_list.append(cost_samp)\n",
    "        cost_gt_list.append(cost_gts)\n",
    "        print('Time to process {} set of images: {}'.format(image+1,time.time()-start))\n",
    "       \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to find the image which has the lowest cost. Stack them all togerther and take the argmax(since its negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare = cost_samp_list[0]\n",
    "\n",
    "compare =compare.reshape(1000,1)\n",
    "count = 1\n",
    "for i in range(len(cost_samp_list)-1):\n",
    "    #pdb.set_trace()\n",
    "    compare = np.append(compare,cost_samp_list[count].reshape(1000,1),axis=1)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = np.argmax(compare, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the possible sequence in an array\n",
    "list_miss_numbers = []\n",
    "\n",
    "list_miss_numbers.append([0,0,0,0])\n",
    "list_miss_numbers.append([1,0,0,0])\n",
    "list_miss_numbers.append([0,1,0,0])\n",
    "list_miss_numbers.append([0,0,1,0])\n",
    "list_miss_numbers.append([0,0,0,1])\n",
    "list_miss_numbers.append([1,1,0,0])\n",
    "list_miss_numbers.append([1,0,1,0])\n",
    "list_miss_numbers.append([1,0,0,1])\n",
    "list_miss_numbers.append([0,1,1,0])\n",
    "list_miss_numbers.append([0,1,0,1])\n",
    "list_miss_numbers.append([0,0,1,1])\n",
    "list_miss_numbers.append([1,1,1,0])\n",
    "list_miss_numbers.append([1,1,0,1])\n",
    "list_miss_numbers.append([1,0,1,1])\n",
    "list_miss_numbers.append([0,1,1,1])\n",
    "list_miss_numbers.append([1,1,1,1])\n",
    "\n",
    "list_miss_numbers = np.asarray(list_miss_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to do the same as one pixel case but need to compare over 16 images. Each does the same but for the specific sequnece. Here the smapled cost and ground truth cost are calculated for the predicted list of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_Xent = 0\n",
    "gt_Xent =0\n",
    "pred_image = []\n",
    "accuracy = 0\n",
    "accuracy_pixel = 0\n",
    "count =0\n",
    "\n",
    "mistake_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    if predictions[i]==0:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "                \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==1:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "\n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "    elif predictions[i]==2:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "    elif predictions[i]==3:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==4:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "            \n",
    "    elif predictions[i]==5:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==6:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==7:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==8:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==9:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==10:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==11:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==12:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==13:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==14:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)\n",
    "            \n",
    "    elif predictions[i]==15:\n",
    "        k = predictions[i]\n",
    "        ml_Xent += -cost_samp_list[k][i]\n",
    "        gt_Xent += -cost_gt_list[k][i]\n",
    "        pred_image.append(pixel_list[k][i,:])\n",
    "        count+=1\n",
    "        for pix in range (4):\n",
    "            if list_miss_numbers[k,pix] == pic_GT[i, miss_pix_ind[i,pix]]:\n",
    "                accuracy_pixel+=1\n",
    "        \n",
    "        if all(list_miss_numbers[k,:] == pic_GT[i, miss_pix_ind[i,:]]):\n",
    "            accuracy +=1\n",
    "        else:            \n",
    "            mistake_list.append(i)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum likelihood average loss is: 60.7339\n",
      "The ground truth average loss is: 60.954\n",
      "The number of correctly patches is : 79.7%\n",
      "The number of correctly pixels is : 93.4%\n"
     ]
    }
   ],
   "source": [
    "print('The maximum likelihood average loss is: {:.6}'.format(ml_Xent/1000))\n",
    "print('The ground truth average loss is: {:.6}'.format(gt_Xent/1000))\n",
    "print('The number of correctly patches is : {:.1%}'.format(accuracy/1000))\n",
    "print('The number of correctly pixels is : {:.1%}'.format(accuracy_pixel/4000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_images = np.asarray(pred_image)\n",
    "submit_images =submit_images.reshape(1,1000,784)\n",
    "submit_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_inpaintings = np.append(twobytwopixels_inpainting,submit_images,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save('2X2_pixels_inpainting.npy', new_inpaintings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reloaded_model =  np.load('2X2_pixels_inpainting.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAEICAYAAABlM/5GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x184da2d7d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_images = reloaded_model[2,:,:]\n",
    "gt_images = reloaded_model[1,:,:]\n",
    "masked_images = reloaded_model[0,:,:]\n",
    "f2, axar = plt.subplots(2, 3)\n",
    "\n",
    "#correct images\n",
    "for i in range(3):\n",
    "    axar[0, i].imshow(my_images[i,:].reshape(28,28))\n",
    "    axar[0, i].set_title('Pred {}'.format(i))\n",
    "    axar[0, i].axis('off')\n",
    "\n",
    "    axar[1, i].imshow(gt_images[i,:].reshape(28,28))\n",
    "    axar[1, i].set_title('GT {}'.format(i))\n",
    "    axar[1, i].axis('off')\n",
    "    \n",
    "f2.subplots_adjust(hspace=0.7)\n",
    "#plt.savefig('C:/Users/Alex/.ipython/CW2/models/Task2/images/2by2_good.png', dpi =150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEICAYAAADFrJaoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhpIE2AwlCbAZShJgM5QkwGYoSQD8H3uuxG3U+eB0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x184da29d518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f2, axar = plt.subplots(3, 3)\n",
    "#mistakes\n",
    "for i in range(3):\n",
    "    axar[0, i].imshow(my_images[mistake_list[i],:].reshape(28,28))\n",
    "    axar[0, i].set_title('Pred {}'.format(i))\n",
    "    axar[0, i].axis('off')\n",
    "    \n",
    "    axar[1, i].imshow(masked_images[mistake_list[i],:].reshape(28,28))\n",
    "    axar[1, i].set_title('mask {}'.format(i))\n",
    "    axar[1, i].axis('off')    \n",
    "    \n",
    "    \n",
    "    axar[2, i].imshow(gt_images[mistake_list[i],:].reshape(28,28))\n",
    "    axar[2, i].set_title('GT {}'.format(i))\n",
    "    axar[2, i].axis('off')\n",
    "    \n",
    "f2.subplots_adjust(hspace=0.7)\n",
    "#plt.savefig('C:/Users/Alex/.ipython/CW2/models/Task2/images/2by2_mistake.png', dpi =150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
